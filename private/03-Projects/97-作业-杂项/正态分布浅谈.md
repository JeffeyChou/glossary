---
title: Untitled
date: 2022-10-29 16:10:07
excerpt: 
tags: 正态分布 最大似然估计
rating: ⭐
status: complete 
destination: 03-97
share: false
obsidianUIMode: source
---
[source](https://zhuanlan.zhihu.com/p/558880948)

**Physicists believe that the Gaussian law has been proved in mathematics while mathematicians think that it was experimentally established in physics.** --- Henri Poincaré

物理学家认为 #正态分布(高斯分布)已经在数学上得到证明，而数学家则认为其在物理试验中得到确认。

---

众所周知，懂一点点概率与统计对理解反问题(地球物理反演、机器学习)是必需的。本文主要介绍正态分布的来龙去脉, 及相关重要概念。为什么会有不同的分布呢？下面通过一张图简要说明分布的重要性。
![[Pasted image 20221029161059.png]]
在生活中，为了做出更好的决策，我们需理性分析，而分析就需要数据与模型。

如上图所示，1) 数据是根据相应方法采样得到的；2) 通过对数据的统计分析，我们能创造出相应的数学模型；3)根据模型，我们能计算决策满足的概率，据此，我们做出较理性的决策。

同时，我们有时需根据已创造的模型(伪)随机地生成大量数据进行实验，如蒙特卡洛类方法。再者，通过对大量数据的分析与处理，我们也能直接做出相应的决策，这就是 #大数据思想 ，即 Learning from data.

在此过程中，我们应该时刻记得以下几点：

1）**数据是上帝给的，模型是人造的**；

2）**所有模型都是错的，但有一些是有用的**。

3) **No data, No Truth.**

在此过程中，知道数据的分布类型对**统计分析**及**创造合适的数学模型**都至关重要。在某种程度上讲，各种分布也是人类创造的数学模型。

## 1 正态分布
### 1.1 性质

正态分布(Normal distribution) 又叫高斯分布，由于其在自然界中广泛存在，具有很本质的特性(如 #最大熵) 与稳定的性质，其是所有分布里用途最广的，也是很多分布的基础。这些稳定的性质包括：

-   任何具有单个舍入最大值的光滑函数，如果提高到越来越高的幂次，就变成高斯函数(正态分布)。(Any smooth function with a single rounded maximum, if raised to higher and higher powers, goes into a Gaussian function. ---Jaynes)
-   两个正态分布的**乘积**和**卷积**都是正态分布；
-   正态分布的**傅里叶变换**还是正态分布；
-   正态分布和其它具有相同均值、方差的分布相比，具有**最大熵**；
-   **中心极限定理**保证了多个随机变量的求和效应将导致正态分布;
-   若X,Y是独立的随机变量，S=X+Y是正态分布，则X，Y都是正态分布 (克拉美分解定理)，反之亦然;
-   **随机扩散过程**能用高斯函数(正态分布)完美描述。

关于 #中心极限定理 通俗解释，可参考：

[怎样理解和区分中心极限定理与大数定律？12 赞同 · 0 评论回答![](https://pic4.zhimg.com/v2-6be4a53cd7cf57978ae8bff73f3abdeb_180x120.jpg)](https://www.zhihu.com/question/22913867/answer/2409687811)

---

同时，当n很大时，许多其他分布也趋向于正态分布，**正态分布是多种分布之母**。换言之，**正态分布就像一个黑洞**，其他概率分布在各种形式操作之下都将趋近于正态分布(Jaynes观点)。

-   **二项分布**的极限是正态分布(如高尔顿钉板)；
- 当 λ 较大时， #泊松分布 逼近正态分布；
-   当n很大时， #卡方分布 逼近正态分布；
-   当n很大时， #t分布 逼近标准正态分布；
-   #二项分布 的极限是正态分布(如 #高尔顿钉板)；
-   当 $\lambda$ 较大时，**泊松分布**逼近正态分布；
-   当n很大时，**卡方分布**逼近正态分布；
-   当n很大时，**t分布**逼近标准正态分布；
-   当n很大时， #最大似然估计 的结果趋近于正态分布 (最小二乘基础)；

![](https://pic3.zhimg.com/80/v2-a14bc52b8550490c2af92ba41cb3e41e_1440w.webp)

高尔顿钉板 (Galton board)

### 1.2 历史

1) 棣莫弗(1667-1754), 拉普拉斯(1749-1827)通过研究二项分布发现：**二项分布的极限是正态分布**，这就是**棣莫弗-拉普拉斯中心极限定理。**

2) 高斯(1777-1855), 基于极大似然估计思想拓展了最小二乘法，即：

**误差分布导出的极大似然估计(Maximum Likelihood Estimate)=算术平均值((arithmetic mean)**

据此，高斯精确算出了概率密度函数 f 解析表达式 (也就是正态分布概率密度表达式)，即**误差服从正态分布**。

$f(x)=\frac{1}{ \sigma\sqrt{2\pi}}e^{-\frac{(x-\mu)^2}{2\sigma^2}}$

**注：极大似然估计(Maximum Likelihood Estimate)基本思想是：选择合适的参数，让联合概率密度最大**。

高斯推导告诉我们：当数据误差为独立、正态分布时，极大似然解就是最小二乘解。

因此，在正态分布的发现过程中，**棣莫弗、拉普拉斯与高斯**都有相应的贡献。有趣的是，为了争论优先权，该分布在法国叫拉普拉斯分布，在德国叫高斯分布，在其他国家叫拉普拉斯-高斯分布。后来， #庞加莱 (Poincaré)建议改用正态分布这一中立名称。随后，**皮尔森**使得这一名字被广泛接受。

_Many years ago I called the Laplace-Gaussian curve the normal curve, which name, while it avoids an international question of priority, has the disadvantage of leading people to believe that all other distributions of frequency are in one sense or another“abnormal”. ---_ **Karl Pearson (1920)**

![](https://pic2.zhimg.com/80/v2-6b570ea02b14abaff26e38b000edbf79_1440w.webp)

图片来源Wikipedia

---

**数学是上帝的语言** ---高斯
### 1.3 高斯的推导

出发点：**误差分布导出的极大似然估计(Maximum Likelihood Estimate)=算术平均值((arithmetic mean)**
设真值为$\theta , x_1,x_2,...,x_n$ 为 n 次独立测量值, 每次测量的误差为$e_i=x_i-\theta$ .若单个误差 $e_i$ 的概率密度函数为 $f(e_i)$ ,则n个测量的联合概率密度函数为：

$f(e_1)f(e_2)...f(e_n)=f(x_1-\theta)f(x_2-\theta)...f(x_n-\theta)$

记似然函数为：

$L(\theta;x_1,x_2,...,x_n)=f(x_1-\theta)f(x_2-\theta)...f(x_n-\theta)$

上式取对数得：

$\log L =\log f(x_1-\theta)+\log f(x_2-\theta)+...+\log f(x_n-\theta)$

要求得极大似然估计(未知量为待估计的真值 $\theta$ , 即求 $\log ⁡L$ 的最大值，则，

$\frac{ \partial \log L}{\partial \theta} = 0$

则，

$\frac{1}{f(x_1-\theta)}\frac{df(x_1-\theta)}{d(x_1-\theta)}\frac{\partial (x_1-\theta)}{\partial \theta}+...+\frac{1}{f(x_n-\theta)}\frac{df(x_n-\theta)}{d(x_n-\theta)}\frac{\partial (x_n-\theta)}{\partial \theta}=0$

整理一下得，

$\frac{f'(x_1-\theta)}{f(x_1-\theta)}+...+\frac{f'(x_n-\theta)}{f(x_n-\theta)}=0$

令，

$g(x)=\frac{f'(x)}{f(x)}$

则上式转化为：

$g(x_1-\theta)+...+g(x_n-\theta) = 0$

根据假设，要求的解 θ 应该为算术平均值 x¯ ，则， 

$g(x_1-\bar{x})+...+g(x_n-\bar{x})=0$

此处有个技巧：

1) 先取两项看看 g(x) 具有何种性质，此时，

$\bar{x}=\frac{1}{2}(x_1+x_2)\Rightarrow x_1-\bar{x}=-(x_2-\bar{x})$

同时，原式为，

$g(x_1-\bar{x})+g(x_2-\bar{x})=0$

$\Rightarrow g(x_1-\bar{x})=-g(x_2-\bar{x})=-g[-(x_1-\bar{x})]$

这说明，$g(-x)=-g(x)$

2) 此时取前m项为， $x_1=x_2=...x_m = -x$，

第$m+1$项为， $x_{m+1}=mx$ ，

则， $\bar{x}=0$ ，

且 , $g(x_1)+g(x_2)+...+g(x_m)+g(x_{m+1})=0$

$\Rightarrow mg(-x)+g(mx)=0$

利用前面得到的$g(x)$的性质,

$mg(x)=g(mx)$

满足上式的解为，

$g(x)=bx \Rightarrow \frac{f'(x-\theta)}{f(x-\theta)} =b(x-\theta)$

从而求得概率分布函数为,

$f(x)=ae^{\frac{1}{2}b(x-\theta)^2}$

从物理上讲:

a) **当测量值 $x$ 离真值 $\theta$ 越远时，其概率密度应该越小**，则原式系数b应该为负数，则

$f(x)=ae^{-\frac{1}{2}b(x-\theta)^2}$ (此处b>0)

b) **概率密度函数在定义域的积分应该为1**，则

$\int_{-\infty}^{+\infty} f(x)dx = 1$

由恒等式

$\int_{-\infty}^{+\infty}e^{-\lambda x^2}dx = \sqrt{\frac{\pi}{\lambda}} , ( \lambda >0)$，此式详细推导参考：[Hsuty：广义函数之狄拉克函数](https://zhuanlan.zhihu.com/p/345809392)。

因此，原式

$\int_{-\infty}^{+\infty} ae^{-\frac{1}{2}b(x-\theta)^2}dx = a\sqrt{\frac{2\pi}{b}}=1$

$\Rightarrow a=\sqrt{\frac{b}{2\pi}}$

$f(x)=\sqrt{\frac{b}{2\pi}}e^{-\frac{1}{2}b(x-\theta)^2}$

此时，不妨令

$\sigma^2=\frac{1}{b}$

则，

$f(x)=\frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{1}{2}\frac{(x-\theta)^2}{\sigma^2}}$

由此，得到了概率密度函数解析表达式，形式和高斯函数一模一样。

**小结**：高斯利用当时人们常用的多次测量取平均的方法，**创造性地提出极大似然函数估计就等于算术平均**，从而推导出了正态分布解析表达式。在此过程中，**充分利用物理条件**，求得各待定系数具体表达式。

---

**延伸**：从推导出的概率密度可以看出，释然函数为，

$L(\theta;x_1,x_2,...,x_n)=(\frac{1}{\sqrt{2\pi\sigma^2}})^n\prod_{i=1}^{n}e^{-\frac{1}{2}\frac{(x_i-\theta)^2}{\sigma^2}}$

取个对数，

$\ln L=(\frac{1}{\sqrt{2\pi\sigma^2}})^n\sum_{n}^{i=1}{-\frac{1}{2}\frac{(x_i-\theta)^2}{\sigma^2}}$

要让 $\ln L$ 取极大值，则

$\sum_{n}^{i=1}{\frac{(x_i-\theta)^2}{\sigma^2}}$

应该取最小值。这不就是**最小二乘法**吗？

因此：**当数据误差为独立、正态分布时，极大似然解就是最小二乘解。**

---

### 1.4 随机扩散解

**下面讨论一个随机扩散过程，通过推导，我们可以发现随机扩散过程的解就是高斯函数**。

![动图封面](https://pic3.zhimg.com/v2-1ca00dbd7de555a88afe910977efe706_b.webp)

**问题描述**：在一维情况下，假设任一粒子在很短的时间 $\tau$ 内运动到$+y$那么远的距离概率密度为 $\rho(y)$ ,此概率密度具有如下性质：

$\rho(y)\geq 0$

$\int_{-\infty}^{+\infty}\rho(y)dy=1$

进一步假设：

$\rho(y)=\rho(-y)$

即，粒子往+y跑的概率与往-y跑的概率相同，则，

$\int_{-\infty}^{+\infty}y\rho(y)dy=0$ (被积函数为奇函数).

同时，令，

$\int_{-\infty}^{+\infty}y^2\rho(y)dy=D$

在$t$时刻，某具体位置$x$上的粒子数设为：$f(x,t)$,

根据连续性条件：在某具体位置$x$， $t+\tau$ 时刻的粒子数量为：

$f(x,t+\tau)=C_1\int_{-\infty}^{+\infty}f(x-y,t)\rho(y)dy+C_2\int_{-\infty}^{+\infty}f(x+y,t)\rho(-y)dy+f(x,t)$

$-C_3 \int_{-\infty}^{+\infty}f(x,t)\rho(y)dy-C_4\int_{-\infty}^{+\infty}f(x,t)\rho(-y)dy$

此式子意思为：在$x$位置，$t+\tau$ 时刻的粒子数量为从+y方向来的，加上从-y方向来的，加上x位置t时刻有的,减去从+y方向与-y方向出去的。C为系数，且 $C_1+C_2=1,C_3+C_4=1$ ，用于调节从+y方向来的(或出去的)与-y方向来的(或出去的)分配比例。

根据泰勒展开式(**注意小量**为 $\tau,y$ )：

$f(x,t+\tau)=f(x,t)+\frac{\partial f}{\partial t}\tau +o(\tau)$

$f(x-y,t)=f(x,t)-\frac{\partial f}{\partial x}y+\frac{1}{2}\frac{\partial ^2f}{\partial x^2}y^2+o(y^2)$

$f(x+y,t)=f(x,t)+\frac{\partial f}{\partial x}y+\frac{1}{2}\frac{\partial ^2f}{\partial x^2}y^2+o(y^2)$

因此，

$f(x,t)+\frac{\partial f}{\partial t}\tau=C_1 \int_{-\infty}^{+\infty}\left\{ f(x,t)-\frac{\partial f}{\partial x}y+\frac{1}{2}\frac{\partial ^2f}{\partial x^2}y^2 \right\}\rho(y)dy+f(x,t)$

$+C_2\int_{-\infty}^{+\infty}\left\{ f(x,t)+\frac{\partial f}{\partial x}y+\frac{1}{2}\frac{\partial ^2f}{\partial x^2}y^2 \right\}\rho(-y)dy$

$-C_3\int_{-\infty}^{+\infty}f(x,t)\rho(y)dy-C_4\int_{-\infty}^{+\infty}f(x,t)\rho(-y)dy$

注意：

$\int_{-\infty}^{+\infty}\rho(y)dy=1$

$\int_{-\infty}^{+\infty}y\rho(y)dy=0$

$\int_{-\infty}^{+\infty}y^2\rho(y)dy=D$

整理得：

$\frac{\partial f(x,t)}{\partial t} = \frac{D}{2 \tau}\frac{\partial^2 f(x,t)}{\partial x^2}=c\frac{\partial^2 f(x,t)}{\partial x^2}$

这就是**扩散方程**，下面求解此方程，把此方程变换到波数域为：

$\frac{\partial F(k,t)}{\partial t} = c(-ik)^2F(k,t)=-ck^2F(k,t)$

其中，

$F(k,t)=\int_{-\infty}^{+\infty}f(x,t)e^{-ikx}dx$

上式解为：

$F(k,t)=C_5e^{-ck^2t}$

结合初始条件($t=0$时从$x$处开始扩散)，

$f(x,0)=\delta(x)\Rightarrow F(k,0)=1$

得到 $C_5=1$

$F(k,t)=e^{-ck^2t}$

通过反傅里叶变换，

$f(x,t)=\frac{1}{2\pi}\int_{-\infty}^{+\infty}F(k,t)e^{ikx}dk$

得到，

$f(x,t)=\frac{1}{2\pi}\int_{-\infty}^{+\infty}e^{-ck^2t}e^{ikx}dk$

该积分较为复杂，可利用相关软件进行计算，得，

$f(x,t)= \frac{1}{\sqrt{4\pi ct}}e^{-\frac{x^2}{4ct}}$

令，

$2ct=\sigma^2$

则，

$f(x)=\frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{1}{2}\frac{x^2}{\sigma^2}}$

这再次得到了高斯函数表达式。

这说明：扩散方程的解是一个高斯函数，**随机扩散过程能用正态分布(高斯函数)完美描述**。

---

一般地，**利用场的观点**来推导随机扩散过程更为简单。之所以会发生扩散，就是因为物理场存在梯度差，不妨令在 $\vec x$ 位置，t时刻场的密度为$\rho(\vec x,t)$ ，随着扩散进行，场密度改变量为，

$\frac{\partial \rho(\vec x,t)}{\partial t}$

根据散度的定义，场密度改变量等于通量$\vec F (flux)$的散度,即。

$\frac{\partial \rho(\vec x,t)}{\partial t}=-\nabla \cdot \vec F$

此处前面为负号的原因为：**流出散度为正，但场密度减小**。

[Hsuty：梯度、散度、旋度与矢量分析667 赞同 · 42 评论文章![](https://pic2.zhimg.com/v2-f0ba1bd9658892c65c532bdce63c9bb1_180x120.jpg)](https://zhuanlan.zhihu.com/p/165479232)

根据通量定义，可得：

$\vec F=-A\nabla\rho(\vec x ,t)$

系数A代表扩散的空间距离，

带入上式可得：

$\frac{\partial \rho(\vec x,t)}{\partial t}=-\nabla \cdot (-A\nabla\rho)=A \nabla^2 \rho$

从而得到一般情况下(不局限于特定的维度)**扩散方程**：

  
$\frac{\partial \rho(\vec x,t)}{\partial t}=A \nabla^2 \rho(x,t)$

  

上式左端若为对时间的二阶导，那就成了**波动方程**；

---

## 2 单变量正态分布

### 2.1 概率密度

单变量的正态分布解析表达式为(均值为 $\mu$ ，方差为 $\sigma^2$ )：

$f(x)=\frac{1}{\sigma\sqrt{2\pi}}e^{-\frac{1}{2}\frac{(x-\mu)^2}{\sigma^2}}$

图像为：

![](https://pic1.zhimg.com/80/v2-569e7fab8d92e139645303ad229949b4_1440w.webp)

图片来源Wikipedia

**特点**：

1)方差越大，图像越扁，反之越尖;

2)图像关于均值对称；

3)函数从负无穷到正无穷积分值为1.

### 2.2 累积分布函数

对于标准正态分布，

$f(x)=\frac{1}{\sqrt{2\pi}}e^{-\frac{1}{2}x^2}$

概率密度函数的累积分布函数为：

$\Phi(x)=\int_{-\infty}^{x}\frac{1}{\sqrt{2\pi}}e^{-\frac{1}{2}u^2}du$

$=\int_{-\infty}^{0}\frac{1}{\sqrt{2\pi}}e^{-\frac{1}{2}u^2}du+\int_{0}^{x}\frac{1}{\sqrt{2\pi}}e^{-\frac{1}{2}u^2}du$

$=\frac{1}{2}+\int_{0}^{x}\frac{1}{\sqrt{2\pi}}e^{-\frac{1}{2}u^2}du$

定义特殊函数**error function(误差函数)** $erf(x)$,

$erf(x)=\frac{2}{\sqrt{\pi}}\int_{0}^{x}e^{-t^2}dt$

令 $\frac{1}{2}u^2=t^2\Rightarrow u=\sqrt{2}t, du=\sqrt{2}dt$ ,

原来$du$到$x$，现在$dt$就到 $\frac{x}{\sqrt{2}}$ ，则，

**【换元三部曲：1）积分上下限，2）函数变量替换；3）处理微元d。】**

$\int_{0}^{x}\frac{1}{\sqrt{2\pi}}e^{-\frac{1}{2}u^2}du$

$=\int_{0}^{\frac{x}{\sqrt{2}}}\frac{1}{\sqrt{2\pi}}e^{-t^2}(\sqrt{2}dt)$

$=\frac{1}{2}\frac{2}{\sqrt{\pi}}\int_{0}^{\frac{x}{\sqrt{2}}}e^{-t^2}dt$

$=\frac{1}{2}erf(\frac{x}{\sqrt{2}})$

因此，

$\Phi(x)=\frac{1}{2}(1+erf(\frac{x}{\sqrt{2}}))$

一般地，

$\Phi(x)=\frac{1}{2}(1+erf(\frac{x-\mu}{\sigma\sqrt{2}})) 。$

**误差函数图像**：

![](https://pic1.zhimg.com/80/v2-a658981615d50ffdc818ed1f4062d13c_1440w.webp)

erf(x)为奇函数

**概率密度累积分布函数 \Phi(x) 图像**：

![](https://pic4.zhimg.com/80/v2-0dac760eeadc6c1f1a554ce8bd27216f_1440w.webp)

方差越大,累积到1就越缓慢 ，(图片来源Wikipedia)

![](https://pic3.zhimg.com/80/v2-ecb090655b014d28dd58c00c8025f8ae_1440w.webp)

## 3 多变量正态分布

对于多种变量的情况, $\mathbf X=(X_1,X_2,...,X_n)^T$ ，就需要刻画变量间的相互程度，需引入**协方差矩阵(covariance matrix)**,

$\Sigma_{i,j}=Cov(X_i,X_j)$

协方差矩阵具体求法与表达式可参考：[Hsuty：什么是主成分分析(PCA)](https://zhuanlan.zhihu.com/p/473417003)

当多种变量 $\mathbf X$ 满足正态分布时， $\mathbf X\sim N(\mathbf \mu, \mathbf \Sigma)$ ,概率密度函数为：

$f_X(X_1,X_2,...X_n)=\frac{1}{\sqrt{(2\pi)^ndet(\mathbf\Sigma)}}e^{-\frac{1}{2}(\mathbf X-\mathbf \mu)^T\mathbf \Sigma^{-1} (\mathbf X-\mathbf \mu)}$

**图像**：

![](https://pic3.zhimg.com/80/v2-363cd1ced0d8672d961bbd21735c9bb2_1440w.webp)

两种变量的正态分布图像

![](https://pic2.zhimg.com/v2-6aab61e482e27334f1ecf919d9a21555_r.jpg)

两种变量的正态分布图像

---

若多变量向量 $\mathbf X$ 满足正态分布，且期望为 $\mu$ ，协方差矩阵为 $\mathbf C$ ,

令 $\mathbf Y=\mathbf A\mathbf X$ ,则 $\mathbf Y$ 也是多元正态分布，且多元变量 $\mathbf Y$ 期望与协方差矩阵为：

$E(\mathbf Y)=E(\mathbf A \mathbf X)=\mathbf A E( \mathbf X)=\mathbf A\mu$

$Cov(\mathbf Y)=\mathbf A \mathbf C \mathbf A^T$

根据协方差矩阵定义：

$Cov(\mathbf X,\mathbf Y)=E\left\{ \left[ \mathbf X-E( \mathbf X) \right]\left[ \mathbf Y-E( \mathbf Y) \right]^T\right\}$

$Cov(\mathbf X)=Cov(\mathbf X,\mathbf X)=E\left\{ \left[ \mathbf X-E( \mathbf X) \right]\left[ \mathbf X-E( \mathbf X) \right]^T\right\}$

简单推导一下：

$Cov(\mathbf Y)=Cov(\mathbf A \mathbf X )$

$=E\left\{ \left[ \mathbf A\mathbf X-E( \mathbf A\mathbf X) \right] \left[ \mathbf A\mathbf X-E( \mathbf A\mathbf X) \right]^T\right\}$

$=E\left\{ \left[ \mathbf A(\mathbf X-E(\mathbf X)) \right] \left[ \mathbf X-E(\mathbf X) \right]^T A^T \right\}$

$=\mathbf A E\left\{ \left[ \mathbf X-E(\mathbf X) \right]\left[ \mathbf X-E(\mathbf X) \right]^T \right\}\mathbf A^T$
$=\mathbf A \mathbf C\mathbf A^T$

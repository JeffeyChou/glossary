






































































































































Typesetting math: 37%
JavaScript is disabled on your browser. Please enable JavaScript to use all the features on this page. Skip to main content Skip to article
Elsevier logo ScienceDirect

    Journals & Books 

    Search 

周杰锋 UESTC
周U

    View  PDF
    Download full issue 

Outline

    Highlights
    Abstract
    Keywords
    1. Introduction
    2. Basics of the theory of belief functions
    3. Uncertainty measures in the theory of belief functions
    4. Belief interval distance-based total uncertainty measure
    5. Experiments and simulations
    6. Application of the new total uncertainty measure
    7. Conclusions
    Acknowledgments
    References 

Show full outline
Cited By (162)
Figures (10)

    Fig. 1. The change of total uncertainty measures in Example 2
    Fig. 2. The change of total uncertainty measures in Example 4
    Fig. 3. TUI for those with fixed a+b
    Fig. 4. The change of total uncertainty measures in Example 5
    Fig. 5. The change of total uncertainty measures in Example 6
    Fig. 6. The change of total uncertainty measures in Example 7

Show 4 more figures
Tables (3)

    Table 1
    Table 2
    Table 3 

Elsevier
Knowledge-Based Systems
IF 8.139 Q1 B1 Top EI
Volume 94 , 15 February 2016, Pages 114-123
Knowledge-Based Systems
A new distance-based total uncertainty measure in the theory of belief functions
Author links open overlay panel Yi Yang a , Deqiang Han b
Show more
Add to Mendeley
Share
Cite
https://doi.org/10.1016/j.knosys.2015.11.014 Get rights and content
Highlights

    •

    A new total uncertainty measure in evidence theory is proposed.
    •

    The new measure is directly defined in the evidential framework.
    •

    The new measure is not a generalization of those in the probabilistic framework .
    •

    The belief intervals and distance metric are used for the new measure’s design.
    •

    The new measure has no drawbacks in traditional ones and has desired properties.

Abstract

The theory of belief functions is a very important and effective tool for uncertainty modeling and reasoning, where measures of uncertainty are very crucial for evaluating the degree of uncertainty in a body of evidence. Several uncertainty measures in the theory of belief functions have been proposed. However, existing measures are generalizations of measures in the probabilistic framework. The inconsistency between different frameworks causes limitations to existing measures. To avoid these limitations, in this paper, a new total uncertainty measure is proposed directly in the framework of belief functions theory without changing the theoretical frameworks. The average distance between the belief interval of each singleton and the most uncertain case is used to represent the total uncertainty degree of the given body of evidence. Numerical examples, simulations, applications and related analyses are provided to verify the rationality of our new measure.

    Previous article in issue
    Next article in issue 

Keywords
Belief functions
Evidence theory
Uncertainty measure
Belief interval
Distance of interval
1. Introduction

Dempster–Shafer evidence theory (DST) [1] , also called the theory of belief functions, has been widely used in many applications related to uncertainty modeling and reasoning, e.g., information fusion [2] , pattern classification [3] , [4] , clustering analysis [5] , fault diagnosis [6] , and multiple attribute decision-making (MADM) [7] , [8] .

In the theory of belief functions, there are two types of uncertainty including the discord (or conflict or randomness) [9] and the non-specificity [10] , hence the ambiguity [11] . Various kinds of measures for these two types of uncertainty and the total uncertainty including both two types were proposed. The measures of discord include the discord measure [9] , the strife [9] , the confusion [12] , etc; the measures of non-specificity include Dubois and Prade’s definition [10] generalized from the Hartley entropy [13] in the classical set theory, Yager’s definition [14] , and Korner’s definition [15] , etc. The most representative total uncertainty measures are the aggregated measure ( AU ) [16] and the ambiguity measure ( AM ) [11] .

In essential, no matter AU or AM , they are the generalization of Shannon entropy [17] in probability theory, but not the direct definition in the framework of the theory of belief functions. That is, they pick up a probability according to some criteria or constraints established based on the given body of evidence (BOE), and then calculate the corresponding Shannon entropy of the probability to indirectly depict the degree of uncertainty for the given body of evidence. As mentioned in the related references [11] , [18] , AU and AM have their own limitations. For example, they are insensitive to the change of BBA. These limitations to some extent are related to the inconsistency [19] , [20] between the framework of the theory of belief functions and that of the probability theory. Therefore, to avoid the limitations of the traditional definitions for the uncertainty measure, in our work, a new total uncertainty measure is proposed directly in the framework of the theory of belief functions without the switching between different frameworks. We analyze the belief interval and conclude that belief intervals carry both the randomness part and the imprecision part (non-specificity) in the uncertainty incorporated in a BOE. Thus, it is feasible to define a total uncertainty measure for a BOE. Given a BOE, the distance between the belief interval of each singleton and the most uncertain interval [0, 1] is used for constructing the degree of total uncertainty. The larger the average distance, the smaller the degree of uncertainty. Since there is no switch of theoretical frameworks, our new definition has desired properties including the ideal value range and the monotonicity. Furthermore, the uncertainty measure can provide more rational results when compared with the traditional ones, which can be supported by experimental results and related analyses.

The rest of this paper is organized as follows. Section 2 provides the brief introduction of the theory of belief functions. Commonly used uncertainty measures in the theory of belief functions are introduced in Section 3 . Some drawbacks of the available total uncertainty measures including AM and AU are also pointed out in Section 3 . In Section 4 , a new total uncertainty measure is proposed. Some desired properties and related analyses on the new proposed definition are also provided. Experiments and simulations are provided in Section 5 to show the rationality of our proposed total uncertainty measure. An application of the new total uncertainty measure on feature evaluation is provided in Section 6 . Section 7 concludes this work.
2. Basics of the theory of belief functions

The basic conception in the theory of belief functions [1] is the frame of discernment (FOD), whose elements are mutually exclusive and exhaustive, representing what we concern. m : 2 Θ → [ 0 , 1 ] is called a basic belief assignment (BBA) defined over an FOD Θ if it satisfies (1) ∑ A ⊆ Θ m ( A ) = 1 , m ( ∅ ) = 0 When m ( A ) > 0, A is called a focal element. A BBA is also called a mass function. The set of all the focal elements denoted by F and their corresponding mass assignments constitute a body of evidence (BOE) ( F , m ) .

The belief function ( Bel ) and plausibility function (( Pl )) are defined as (2) B e l ( A ) = ∑ B ⊆ A m ( B ) (3) P l ( A ) = ∑ A ∩ B ≠ ∅ m ( B ) The belief function Bel ( A ) represents the justified specific support for the focal element (or proposition) A , while the plausibility function Pl ( A ) represents the potential specific support for A . The length of the belief interval [ Bel ( A ), Pl ( A )] is used to represent the degree of imprecision for A .

Two independent BBAs m 1 ( · ) and m 2 ( · ) can be combined using Dempster’s rule of combination as [1] (4) m ( A ) = { 0 , £ A = ∅ ∑ A i ∩ B j = A m 1 ( A i ) m 2 ( B j ) 1 − ∑ A i ∩ B j = ∅ m 1 ( A i ) m 2 ( B j ) , £ A ≠ ∅ There are still some other alternative combination rules. See [21] for details. The theory of belief functions has been criticized for its validity [19] , [20] , [22] , [23] , [24] , [25] . It is not a successful generalization of the probability theory, i.e., there exists inconsistency [20] between the framework of the theory of belief functions and that of the probability theory.
3. Uncertainty measures in the theory of belief functions

In the theory of belief functions, there are two types of uncertainty including the discord (or the conflict or the randomness) and the non-specificity, hence ambiguity [11] .
3.1. Measure of discord in belief function

Measures of discord are for describing the randomness (or discord or conflict) in a BOE [11] . Available definitions are listed below. Although with various names, they are all for the discord part of the uncertainty in a BOE.

(1) Confusion measure [12] (5) C o n f ( m ) = − ∑ A ⊆ Θ m ( A ) log 2 ( B e l ( A ) )

(2) Dissonance measure [14] (6) D i s s ( m ) = − ∑ A ⊆ Θ m ( A ) log 2 ( P l ( A ) )

(3) Discord measure [26] (7) D i s c ( m ) = − ∑ A ⊆ Θ m ( A ) log 2 [ 1 − ∑ B ⊆ Θ m ( B ) | B − A | | B | ]

(4) Strife measure [9] (8) S t r i ( m ) = − ∑ A ⊆ Θ m ( A ) log 2 [ 1 − ∑ B ⊆ Θ m ( B ) | A − B | | A | ] Note that all these definitions can be considered as Shannon entropy-alike measures. More detailed information on these measures can be found in [9] .
3.2. Measures for non-specificity in belief function

Non-specificity [15] , [27] means two or more alternatives are left unspecified and represents an imprecision degree. It only focuses on those focal elements with cardinality larger than one. Non-specificity is a special uncertainty type in the framework of belief functions theory when compared with the probabilistic framework . Some non-specificity measures [10] , [14] , [15] were proposed. The most commonly used non-specificity definition is [10] (9) N S ( m ) = ∑ A ⊆ Θ m ( A ) log 2 | A | It can be regarded as a generalized Hartley measure [13] from the classical set theory. When the BBA m ( · ) is a Bayesian BBA, i.e., it only has singleton focal elements, it reaches the minimum value 0. When BBA m ( · ) is a vacuous BBA, i.e., m ( Θ ) = 1 , it reaches the maximum value log 2 (| Θ |). This definition was proved to have the uniqueness by Ramer [28] and it satisfies all the requirements of the non-specificity measure.
3.3. Measures for total uncertainty in belief functions theory

(1) Aggregated Uncertainty ( AU ) [16] (10) A U ( m ) = max [ − ∑ θ ∈ Θ p θ log 2 p θ ] s . t . { p θ ∈ [ 0 , 1 ] , ∀ θ ∈ Θ ∑ θ ∈ Θ p θ = 1 B e l ( A ) ≤ ∑ θ ∈ A p θ ≤ 1 − B e l ( A ¯ ) , ∀ A ⊆ Θ In fact for AU , given a BBA, the probability with the maximum Shannon entropy under the constraints established using the given BBA is selected and its corresponding Shannon entropy value is defined as the value for AU . Therefore, it is also called as “upper entropy” [29] . It is an aggregated total uncertainty (ATU) measure, which captures both non-specificity and discord. AU satisfies all the requirements [29] for uncertainty measure including probability consistency, set consistency, value range, monotonicity, sub-additivity and additivity for the joint BBA in Cartesian space.

(2) Ambiguity Measure ( AM ) [11] (11) A M ( m ) = − ∑ θ ∈ Θ B e t P m ( θ ) log 2 ( B e t P m ( θ ) ) where B e t P m ( θ ) = ∑ θ ∈ B ⊆ Θ m ( B ) / | B | is the pignistic probability [30] of a BBA. In fact AM uses the Shannon entropy of the pignistic probability of a given BBA to represent the uncertainty.
3.4. Drawbacks of available total uncertainty measures for belief functions

The traditional total uncertainty measures have their own drawbacks. AM cannot satisfy the sub-additivity (for joint BBA in Cartesian space) which has been pointed out by Klir and Lewis [18] . Moreover, AM is criticized due to its logical non-monotonicity [29] as shown in Example 1 .
3.4.1. Example 1

Suppose that the FOD is { θ 1 , θ 2 , θ 3 }. There are two BBAs as follows: m 1 ( { θ 1 , θ 2 } ) = 1 / 3 , m 1 ( { θ 1 , θ 3 } ) = 1 / 2 , m 1 ( { θ 2 , θ 3 } ) = 1 / 6 ; m 2 ( { θ 1 , θ 2 , θ 3 } ) = 1 / 3 , m 2 ( { θ 1 , θ 3 } ) = 1 / 2 , m 2 ( { θ 2 , θ 3 } ) = 1 / 6 . Obviously, from the two BBAs, there exists B e l 2 ( A ) ⩽ B e l 1 ( A ) , P l 1 ( A ) ⩽ P l 2 ( A ) , ∀ A ⊆ Θ .

That is to say, all the belief intervals of m 1 can be contained by those corresponding belief intervals of m 2 , which means that m 2 has a higher level of uncertainty. We can calculate their corresponding AM and AU as follows: 1.5546 = A M ( m 1 ) ⩾ A M ( m 2 ) = 1.5100 ; A U ( m 1 ) = A U ( m 2 ) = 1.5850 = l o g 2 3 . We can see that the results of AM are counter-intuitive, because AM violates the monotonicity, i.e., AM decreases the total quantity of uncertainty in this example where a clear increment of uncertainty of m 2 compared with that of m 1 . Although AU does not bring out a decrease of the quantity of uncertainty, it generates two equal values, which is also counter-intuitive, because m 2 should have higher level of uncertainty. We provide further analyses on this example. The belief function and plausibility function of m 1 and m 2 are B e l 1 ( { θ 1 } ) = 0.0000 , P l 1 ( { θ 1 } ) = 0.8333 ; B e l 1 ( { θ 2 } ) = 0.0000 , P l 1 ( { θ 2 } ) = 0.5000 ; B e l 1 ( { θ 1 , θ 2 } ) = 0.3333 , P l 1 ( { θ 1 , θ 2 } ) = 1.0000 ; B e l 1 ( { θ 3 } ) = 0.0000 , P l 1 ( { θ 2 } ) = 0.6667 ; B e l 1 ( { θ 1 , θ 3 } ) = 0.5000 , P l 1 ( { θ 1 , θ 3 } ) = 1.0000 ; B e l 1 ( { θ 2 , θ 3 } ) = 0.1667 , P l 1 ( { θ 1 , θ 3 } ) = 1.0000 ; B e l 1 ( Θ ) = 1.0000 , P l 1 ( Θ ) = 1.0000 ; B e l 2 ( { θ 1 } ) = 0.0000 , P l 2 ( { θ 1 } ) = 0.8333 ; B e l 2 ( { θ 2 } ) = 0.0000 , P l 2 ( { θ 2 } ) = 0.5000 ; B e l 2 ( { θ 1 , θ 2 } ) = 0.0000 , P l 2 ( { θ 1 , θ 2 } ) = 1.0000 ; B e l 2 ( { θ 3 } ) = 0.0000 , P l 2 ( { θ 2 } ) = 0.6667 ; B e l 2 ( { θ 1 , θ 3 } ) = 0.5000 , P l 2 ( { θ 1 , θ 3 } ) = 1.0000 ; B e l 2 ( { θ 2 , θ 3 } ) = 0.1667 , P l 2 ( { θ 1 , θ 3 } ) = 1.0000 ; B e l 2 ( Θ ) = 1.0000 , P l 2 ( Θ ) = 1.0000 .

Since AU tries to find a probability maximizing the Shannon entropy, and the uniform p.m.f. (probability mass function) P ( θ 1 ) = P ( θ 2 ) = P ( θ 3 ) = 1 / 3 , which has the maximum Shannon entropy, satisfies all the constraints (shown in Eq. (10) ) established using Bel 1 , Pl 1 and those using Bel 2 and Pl 2 . Therefore, both AU 1 and AU 2 reach the maximum value l o g 2 3 = 1.5850 .
3.4.2. Example 2

Suppose that the FOD Θ = { θ 1 , θ 2 } . A BBA over Θ is m ( { θ 1 } ) = a , m ( { θ 2 } ) = b , m ( { Θ } ) = 1 − a − b , where a, b ∈ [0, 0.5]. Here, we calculate AU, AM values corresponding to different values of a and b . The change of AU and AM values with the change of a and b are illustrated in Fig. 1 .
Fig. 1

    Download : Download high-res image (620KB)
    Download : Download full-size image 

Fig. 1 . The change of total uncertainty measures in Example 2 .

As shown in Fig. 1 , AM reaches its maximum when a = b , because when a = b (no matter a or b ’s value is large or small), the pignistic probability is uniformly distributed. This is counter-intuitive, because AM cannot discern the effect of total set’s mass assignment values to the uncertainty degree. For example, m 1 ( { θ 1 } ) = m 1 ( { θ 2 } ) = 0.5 and m 2 ( { θ 1 } ) = m 2 ( { θ 2 } ) = 0.25 , m 2 ( Θ ) = 0.5 , there exists A M ( m 1 ) = A M ( m 2 ) . Obviously, it is irrational to say that m 1 and m 2 have the same degree of total uncertainty. AU never changes with the change of a and b . The value of AU is always l o g 2 2 = 1 . The reason is analyzed as follows. The constraints for calculating AU in this example are B e l ( { θ 1 } ) = a ⩽ P ( θ 1 ) ⩽ 1 − b = P l ( { θ 1 } ) ; B e l ( { θ 2 } ) = b ⩽ P ( θ 2 ) ⩽ 1 − a = P l ( { θ 2 } ) ; B e l ( Θ ) = 1 − a − b ⩽ P ( θ 1 ) ⩽ 1 = P l ( Θ ) ;

Since AU tries to find a p.m.f. with the maximum Shannon entropy, and the uniformly distributed P ( θ 1 ) = P ( θ 2 ) = 0.5 always satisfies the constraints above (because a, b ∈ [0, 0.5]), no matter how a and b change, P ( θ 1 ) = P ( θ 2 ) = 0.5 is always picked up when calculating AU and thus, AU always equals to l o g 2 2 = 1 . However, intuitively, the degree of uncertainty should change with the change of a and b . So, AU cannot well describe the degree of total uncertainty here.

As we can see above, both AM and AU borrow the uncertainty measure (Shannon entropy) in the probability theory framework and they both have drawbacks. However, as aforementioned, the belief functions theory is not a successful generalization of the probability theory. There exists inconsistency between the two frameworks. We do not prefer such a switch between different frameworks, which might cause problems in representing the uncertainty in belief functions. Therefore, in our work, we design the total uncertainty measure directly in the framework of belief functions theory as introduced in the next section.
4. Belief interval distance-based total uncertainty measure
4.1. Belief interval and uncertainty

The belief interval [1] [ Bel ( A, Pl ( A )] of a given focal elements A in a BBA m can represent its uncertainty degree as analyzed below.

Case I: The most uncertain case is B e l ( A ) = 0 and P l ( A ) = 1 , i.e., the belief interval is [0,1].

Case II: The clearest case is B e l ( A ) = 1 and P l ( A ) = 1 ( A is assure to occur) or B e l ( A ) = 0 and P l ( A ) = 0 ( A is assure to never occur).

Case III: When B e l ( A ) = a , P l ( A ) = b , ∀ a, b ∈ (0, 1), the belief interval is [ a, b ]. For A , the degree of imprecision can be represented by b − a , the probability of whether A occurs or not (randomness) is large than a and less than b .

Case IV: When B e l ( A ) = P l ( A ) = a , ∀ a ∈ (0, 1), the belief interval is [ a, a ]. It means that A has no imprecision and whether A occurs or not cannot be clearly determined (it is with the randomness, i.e., the probability a ).

Therefore, the information related to the uncertainty carried by a belief interval both include the randomness part and the imprecision part (non-specificity). Thus, given a BBA, we can fully utilize the information of the belief intervals to measure the total uncertainty of the BBA. Then, how to use the information of belief intervals?

Given the belief interval of A , i.e., [ Bel ( A ), Pl ( A )], if the belief interval is farther from the most uncertain case [0,1], then A has smaller uncertainty; if the belief interval is nearer to the most uncertain case [0,1], then A has larger uncertainty. Then, how to describe the distance between belief intervals? Here we use the distance between interval numbers [31] , [32] as follows. Given two interval numbers [ a 1 , b 1 ] and [ a 2 , b 2 ], a strict distance is defined as (12) d I ( [ a 1 , b 1 ] , [ a 2 , b 2 ] ) = [ a 1 + b 1 2 − a 2 + b 2 2 ] 2 + 1 3 [ b 1 − a 1 2 − b 2 − a 2 2 ] 2

The belief interval [ Bel ( A ), Pl ( A )] can be considered as an interval number. If we replace [ a 1 , b 1 ] by [ Bel ( A ), Pl ( A )] and [ a 2 , b 2 ] by [0, 1], then, the distance obtained can be used to represent how far it is from A to the most uncertain case. As shown in Eq. (12) , in d I , the proportion of [ ( B e l ( { θ i } ) + P l ( { θ i } ) ) / 2 − 1 ] 2 and [ ( P l ( { θ i } ) − B e l ( { θ i } ) ) / 2 − 1 ] 2 is 1/3. Generally speaking, an interval number is a kind of fuzzy data [31] . To define the distance between two fuzzy data, the value of such a proportion depends on the shape [31] (could be the symmetric triangular, normal, parabolic, square root fuzzy data, and interval number) of the fuzzy data model. Here, we use the belief intervals (interval numbers), therefore, there is a rational and natural assumption that the interval is with a uniform distribution. Under such an assumption, the proportion should be 1/3 and d I corresponds to Mallows’ distance between two distributions, hence a strict distance metric for interval numbers. By using such a strict distance metric for interval numbers, we can further define a total uncertainty measure for a BOE as follows.
4.2. New total uncertainty measure based on belief intervals

Suppose that m is a BBA over the FOD Θ = { θ 1 , … , θ n } . First, calculate the belief interval [ Bel ({ θ i }), Pl ({ θ i )}] , i = 1 , … , n for each singleton θ i . Then, calculate the distance between each [ Bel ({ θ i }), Pl ({ θ i )}] and [0, 1], which represents the degree of departure from the most uncertain case for each singleton. Since larger distance (larger departure from the most uncertain case) means smaller total uncertainty, one minus the normalized and averaged belief interval distances (for all singletons) is used as the total uncertainty measure for the BBA m as shown in Eq. (13) (13) T U I ( m ) = 1 − 1 n · 3 · ∑ i = 1 n d I ( [ B e l ( { θ i } ) , P l ( { θ i } ) ] , [ 0 , 1 ] ) where 3 is the normalization factor 1 .

The newly proposed TU I has no drawbacks as those of AU and AM pointed out in Examples 1 and 2 . See the Examples 3 and 4 in Section 5 for details.

Here, we provide an illustrative example to show how TU I is calculated.

Suppose that FOD is Θ = { θ 1 , θ 2 , θ 3 } . A BBA over Θ is m ( { θ 1 } ) = 0.3 , m ( { θ 2 , θ 3 } ) = 0.5 , m ( Θ ) = 0.2 .

First calculate the belief function and plausibility function for singletons B e l ( { θ 1 } ) = m ( { θ 1 } ) = 0.3 , B e l ( { θ 2 } ) = m ( { θ 2 } ) = 0.0 , B e l ( { θ 3 } ) = m ( { θ 3 } ) = 0.0 , P l ( { θ 1 } ) = m ( { θ 1 } ) + m ( Θ ) = 0.5 , P l ( { θ 2 } ) = m ( { θ 2 , θ 3 } ) + m ( Θ ) = 0.7 , P l ( { θ 3 } ) = m ( { θ 2 , θ 3 } ) + m ( Θ ) = 0.7 .

Then, calculate the distance between each belief interval of singleton and the interval [0, 1] d I ( [ B e l ( { θ 1 } ) , P l ( { θ 1 } ) ] , [ 0 , 1 ] ) = d I ( [ 0.3 , 0.5 ] , [ 0 , 1 ] ) = [ 0.3 + 0.5 2 − 0 + 1 2 ] 2 + 1 3 [ 0.5 − 0.3 2 − 1 − 0 2 ] 2 = 0.2517 ; d I ( [ B e l ( { θ 2 } ) , P l ( { θ 2 } ) ] , [ 0 , 1 ] ) = d I ( [ 0 , 0.7 ] , [ 0 , 1 ] ) = [ 0 + 0.7 2 − 0 + 1 2 ] 2 + 1 3 [ 0.7 − 0 2 − 1 − 0 2 ] 2 = 0.1732 ; d I ( [ B e l ( { θ 3 } ) , P l ( { θ 3 } ) ] , [ 0 , 1 ] ) = d I ( [ 0 , 0.7 ] , [ 0 , 1 ] ) = [ 0 + 0.7 2 − 0 + 1 2 ] 2 + 1 3 [ 0.7 − 0 2 − 1 − 0 2 ] 2 = 0.1732 ;

then T U I = 1 − 3 / 3 · ( 0.2517 + 0.1732 + 0.1732 ) = 0.6547 .
4.3. Desired properties of the new total uncertainty measure
4.3.1. Range

The range of TU I is [0, 1], which is desired for practical use. For a vacuous BBA m ( Θ ) = 1 , all the belief intervals for singletons are [0, 1]. Therefore, by using Eq. (13) , its degree of total uncertainty is 1, which is the maximum. For a categorical BBA m ( θ i ) = 1 , the belief interval for θ i is [1, 1] and those of other singletons are [0, 0]. Therefore, by using Eq. (13) , its degree of total uncertainty is 0, which is the minimum.

Proof of the range: For a vacuous BBA, when using Eq. (13) , T U I = 1 . On the other hand, if T U I = 1 , i.e., all the belief intervals for singletons are [0, 1], the corresponding BBA must be a vacuous one. So the maximum value is unique. If a BBA is not a vacuous one, then some singletons’ belief intervals can be strictly contained by [0, 1]. Therefore, according to Eq. (13) , the corresponding TU I will be smaller than 1. Therefore, the unique maximum value of TU I is 1.

For a categorical BBA m ( θ i ) = 1 , when using Eq. (13) , T U I = 0 . On the other hand, if T U I = 0 , the only possible belief interval for singletons are either [0, 0] or [1, 1]. For a BBA, one and only one belief interval for singleton could be [1, 1]. So, the corresponding BBA should be m ( { θ i } ) = 1 , m ( { θ j } ) = 0 , ∀ j ≠ i , which represents the clearest case. If a BBA is not m ( { θ i } ) = 1 , m ( { θ j } ) = 0 , ∀ j ≠ i , some singletons’ belief intervals are neither [0, 0] nor [1, 1]. Therefore, according to Eq. (13) , the corresponding TU I will be larger than 0. So, the minimum value of TU I is 0.

End of Proof
4.3.2. Monotonicity

Given an uncertainty measure UN and two BBAs m 1 and m 2 , if ∀ A ∈ P ( Θ ) : P l 1 ( A ) ⩽ P l 2 ( A ) , B e l 1 ( A ) ⩾ B e l 2 ( A ) o r ∀ A ∈ P ( Θ ) : [ B e l 1 ( A ) , P l 1 ( A ) ] ⊆ [ B e l 2 ( A ) , P l 2 ( A ) ] there exists UN ( m 1 ) ≤ UN ( m 2 ), then it is said that UN satisfies the monotonicity [29] . The physical meaning of the monotonicity is that an uncertainty measure in the theory of belief functions must not decrease the total quantity of uncertainty in situations where there is a clear decrease in information (increment of uncertainty).

Proof of the monotonicity: For two BBAs defined over the same FOD, if it holds that ∀ A ∈ P ( Θ ) : [ B e l 1 ( A ) , P l 1 ( A ) ] ⊆ [ B e l 2 ( A ) , P l 2 ( A ) ] , then, there exists ∀ θ i ∈ Θ : [ Bel 1 ({ θ i }), Pl 1 ({ θ i })]⊆[ Bel 2 ({ θ i }), Pl 2 ({ θ i })]. According to the property of the distance of interval numbers in Eq. (12) , there exists d I ([ Bel 1 ({ θ i }), Pl 1 ({ θ i })], [0, 1]) ≥ d I ([ Bel 2 ({ θ i }), Pl 2 ({ θ i })], [0, 1]).

Then, according to Eq. (13) , TU I ( m 1 ) ≤ TU I ( m 2 ), i.e., the monotonicity holds.

End of Proof
4.4. On other properties

It is declared in [11] , [29] that AU and AM satisfy the probability consistency and set consistency.

Probability consistency: When m is a Bayesian BBA (all focal elements are singletons), AU reduces to Shannon entropy in probability theory A U ( m ) = A M ( m ) = − ∑ θ ∈ Θ m ( { θ } ) l o g 2 ( m ( { θ } ) )

Set consistency: When m focuses on a single set (i.e., m ( A ) = 1 , ∀ A ⊆ Θ ), AU reduces to a Hartley measure in classical theory A U ( m ) = A M ( m ) = l o g 2 ( | A | )

It should be noted that it is meaningless to apply these two requirements or properties to our new measure. First, our new TU I is designed directly in the framework of belief functions theory, but not a generalization of the measures in probability framework or those in classical set theory. Second, the theory of belief functions is not a successful generalization of the probability theory. It cannot degenerate back to the probability framework. For example, a Bayesian BBA is not a probability but still a special BBA, which cannot satisfy the additivity for mutually exclusive events and cannot satisfy the unity for the total set in Kolmogorov probability axioms [33] . Therefore, the validity and strictness of such a consistency is doubtful.

Furthermore, AU also satisfies the sub-additivity and additivity, which defined for the joint BBA in Cartesian space. In our work, we do not concern the joint BBA in Cartesian space, therefore, we will not analyze the sub-additivity and additivity in this paper.

We will further verify our new total uncertainty measure by examples and simulations in the next section.
5. Experiments and simulations
5.1. Example 3

This Example 3 is a revisiting of Example 1 . Using Eq. (13) , we can obtain that T U I ( m 1 ) = 0.6667 and T U I ( m 2 ) = 0.7778 , i.e., m 2 has a higher level of uncertainty, which is intuitive. It can be proved that TU I satisfy the monotonicity. The proof can be found at Section 4.3.2 .
5.2. Example 4

This Example 4 is a revisiting of Example 2 . Our new total uncertainty measure TU I , non-specificity measure NS , dissonance measure Diss are also calculated. The results are shown in Fig. 2 .
Fig. 2

    Download : Download high-res image (689KB)
    Download : Download full-size image 

Fig. 2 . The change of total uncertainty measures in Example 4 .

AU never changes as analyzed in Example 2 , which is counter-intuitive. AM values never changes, so far as a = b holds, which is also counter-intuitive as aforementioned in Example 2 . As we can see in Fig. 2 , TU I brings out rational results. It reaches the maximum when a = b = 0 , i.e., m ( Θ ) = 1 . When a + b is fixed, the maximum values are reached if a = b holds. For example, suppose that a + b = 0.3 . The TU I values are shown in Fig. 3 . This makes sense, because m ( Θ ) = 1 − ( a + b ) is fixed, the non-specificity part is fixed. When a = b , the conflict part reaches its maximum value.

Note that NS reaches 0 (minimum), when a = b = 0.5 ( m ( Θ ) = 0 ); it reaches 1 (maximum), when a = b = 0 ( m ( Θ ) = 1 ). Diss reaches 1 (maximum), when a = b = 0.5 ; it reaches 0 ( minimum), when a = 0 or b = 0 (no conflict).
5.3. Example 5

Suppose that the FOD is Θ = { θ 1 , θ 2 , θ 3 } and a BBA over Θ is m ( A ) = 1 , ∀ A = Θ . We make changes to the BBA step by step. In each step, m ( Θ ) has a decrease of Δ = 0.05 and each singleton mass m ( { θ i } ) , i = 1 , 2 , 3 has an increase of Δ /3. Finally, m ( Θ ) reaches 0 and m ( { θ i } ) = 1 / 3 . We calculate total uncertainty measures including TU I , AM, AU , non-specificity NS , and dissonance ( Diss ) at each step. The changes of uncertainty values are shown in Fig. 4 .

As we can see in Fig. 4 , with the change of the BBA in each step, the non-specificity changes from the maximum to zero. This is intuitive, because the mass assignments are transferred from the focal elements with larger cardinality to those with smaller cardinality. The measure for conflict, i.e., Diss here, becomes larger and reaches the maximum in the final. This is also intuitive, because the BBA changes from a vacuous BBA (no conflict) to a Bayesian BBA (with uniform distribution on all singletons) in the final. The traditional total uncertainty measures AU and AM never change and they are always at the maximum value. This is counter-intuitive because the total uncertainty degree of a vacuous BBA should be the largest, and thus, it should be larger than that of a Bayesian BBA (even if, it is a Bayesian BBA with uniform distribution on all singletons). The reasons for the irrational results of AU and AM are analyzed as follows. They are both defined based on some probabilistic transformation from BBAs. In this example, for the probabilistic transformation used in AM and AU , the results are always a uniformly distributed probability mass function (p.m.f.): P ( θ i ) = 1 / 3 , i = 1 , 2 , 3 , therefore, AM and AU will never change here. Our new measure TU I provides rational results. It becomes smaller and smaller when the BBA changes from a vacuous one to a Bayesian one as shown in Fig. 2 . Therefore, according to our opinion, it is inappropriate to define total uncertainty measure in the theory of belief functions by indirectly using the uncertainty measure in probability framework, i.e., Shannon entropy. It should be better not to switch the framework but to directly design in the framework of belief functions theory. This is also the motivation of our work in this paper.
5.4. Example 6

The FOD is Θ = { θ 1 , θ 2 , θ 3 } . A BBA over Θ is m ( A ) = 1 , ∀ A = Θ . We make changes to the BBA step by step. In each step, m ( Θ ) has a decrease of Δ = 0.05 and mass assignment of one singleton m ({ θ 1 }) has an increase of Δ = 0.05 . In the final step, m ( Θ ) = 0 and m ( { θ 1 } ) = 1 . We calculate total uncertainty measures including TU I , AM, AU , non-specificity measure NS , and dissonance ( Diss ) of the BBA at each step. The changes of these uncertainty values are shown in Fig. 5 .
Fig. 3

    Download : Download high-res image (186KB)
    Download : Download full-size image 

Fig. 3 . TU I for those with fixed a + b .
Fig. 4

    Download : Download high-res image (195KB)
    Download : Download full-size image 

Fig. 4 . The change of total uncertainty measures in Example 5 .
Fig. 5

    Download : Download high-res image (206KB)
    Download : Download full-size image 

Fig. 5 . The change of total uncertainty measures in Example 6 .

The BBA changes from a vacuous one to a categorical one. As shown in Fig. 5 , non-specificity NS becomes smaller and smaller, which is intuitive. The conflict part Diss is always 0, which is also intuitive, because at most two focal elements are available for the BBA in each step (including { θ 1 } and Θ ), therefore, there is no conflict. AU, AM, TU I all decrease intuitively. However, AU is not sensitive to the BBA’s change at the beginning stage (nearly unchanged). This has already been criticized by Jousselme et al. [11] .
Fig. 6

    Download : Download high-res image (277KB)
    Download : Download full-size image 

Fig. 6 . The change of total uncertainty measures in Example 7 .
5.5. Example 7

Examples 7 – 9 are used for reference from [11] . Suppose that the FOD is Θ = { θ 1 , … , θ 8 } . A BBA over Θ is m ( A ) = 1 , ∀ A = Θ . We make changes to the BBA step by step. In each step, m ( Θ ) has a decrease of Δ = 0.05 , and the mass assignment for one focal element B with cardinality s < 8 has an increase of Δ = 0.05 . In the final step, m ( B ) = 1 . Here, we can set s = 2 , 4 , 6 , respectively. Given an s value, we repeat the whole procedure of BBA change. Under the different s , the changes of values for uncertainty measures including TU I , AM, AU, NS , and Diss are shown in Fig. 6 .

As shown in Fig. 6 , when the mass assignments are transferred to a smaller size focal element, the non-specificity NS intuitively decreases. The total uncertainty AU, AM, TU I all decrease. If s has a smaller value, the total uncertainty and the non-specificity will decrease faster, because the mass assignments are transferred to a smaller size focal element. Comparatively, AU is not sensitive to the change of the BBA. The conflict part ( Diss ) is always 0. The reason is analyzed as follows. At the beginning, the BBA is a vacuous one; in the middle steps, the BBA has two focal elements including the total sets; in the final step, it has only one focal element. Therefore, there is no conflict.
5.6. Example 8

Suppose that the FOD is Θ = { θ 1 , … , θ 10 } . A BBA over Θ is m ( Θ ) = 1 − a , and m ( A ) = a , | A | = s ⩽ 10 . Given an a , and the initial | A | = 1 , we make changes to the BBA step by step. | A | increases by 1 in each step. In the final, the BBA becomes a vacuous one. We set a = 0.3 , 0.5 , 0.8 , respectively. Given an a value, we repeat the whole procedure of BBA change. Under the different a , the changes of values for uncertainty measures including TU I , AM, AU, NS , and Diss are shown in Fig. 7 .
Fig. 7

    Download : Download high-res image (215KB)
    Download : Download full-size image 

Fig. 7 . The change of total uncertainty measures in Example 8 .

As shown in Fig. 7 , non-specificity NS , total uncertainty measures including AU, AM , and our TU I all intuitively increase with the change of BBA at each step. If a has a larger value, they will increase faster, because relatively more mass assignments are transferred to a larger size focal element. Comparatively, AU is not sensitive to the BBA’s change. The conflict part ( Diss ) is zero and never changes. The reason is analyzed as follows. Before the final step, the BBA has two focal elements including the total sets; in the final step, it has only one focal element. Therefore, there is no conflict.
5.7. Example 9

Suppose that the size of an FOD is | Θ | = 5 . Randomly generate 10 BBAs with k , 1 ⩽ k ⩽ 2 5 − 1 focal elements using the algorithm [11] in Table 1 .

Table 1 . Algorithm 1: Random generation of BBA.
Input : Θ : FOD; N max  : Maximum number of focal elements;
Output : m : a BBA
Generate the power set of Θ : P ( Θ ) ;
Generate a random permutation of P ( Θ ) → R ( Θ ) ;
Generate an integer between 1 and N max  → k ;
FOReach First k elements of R ( Θ ) do
 Generate a value within [ 0 , 1 ] → m v ( i ) , i = 1 , … , k ;
END
Normalize the vector m v = [ m v ( 1 ) , … , m v ( 2 ) ] → m v ′
m ( A j ) = m v ′ ( j ) , j = 1 , … , k .

In this simulation, the number of focal elements is set to 15. Those generated BBAs are then combined one by one using Dempster’s rule of combination in Eq. (4) . At each instant t of the evidence combination, the values of NS, AU, AM, Diss , and TU I are calculated. The whole procedure is repeated for 100 times and the averaging values of these different uncertainty measures at different t are shown in Fig. 8 . It is shown that all the uncertainty measures, except for Diss , decrease with the increase of the combination steps. This makes sense, because it is intuitive that the total uncertainty decreases in the information fusion procedure such as the evidence combination. The non-specificity measure drops faster and more significantly than the total uncertainty measures. This is because that in the evidence combination based on Dempster’s rule, the focal elements are split into focal elements with smaller cardinality. Also, since the focal elements are split into smaller size focal elements, the conflict in the BBA will significantly increase at the beginning steps. At the final steps, since there is less further split of focal elements and the consensus effect in combination becomes more dominant, the conflict in the BBA decreases slightly as shown in Fig. 8 .
Fig. 8

    Download : Download high-res image (162KB)
    Download : Download full-size image 

Fig. 8 . The change of total uncertainty measures in Example 8 .
6. Application of the new total uncertainty measure

Here we use our new total uncertainty measure in feature evaluation for pattern classification to further show its rationality.

Three classes of samples are artificially generated. There are 200 samples in each class. Each sample has four dimensions. In each class, each dimension of samples is Gaussian distributed with different mean and standard deviation (Std for short) as shown in Fig. 9 and Table 2 .
Fig. 9

    Download : Download high-res image (326KB)
    Download : Download full-size image 

Fig. 9 . Probability density functions (PDFs) of different features of the samples in three classes.

Table 2 . Gaussian distribution parameters of the samples.
Features	Class 1	Class 2	Class 3
Feature 1	Mean	0	4	5.5
	Std	1	1.2	1.2
Feature 2	Mean	0	5	8
	Std	1	1.2	1.2
Feature 3	Mean	4.8	5	5.2
	Std	1.2	1.2	1.2
Feature 4	Mean	5	5	5
	Std	1.2	1.2	1.2

As shown in Fig. 9 and Table 2 , since the three Gaussian probability density functions (PDFs) in feature 2 are quite well separated, the class discriminability of feature 2 is the best; the class discriminability of feature 4 is the worst (totally overlapped), and that of the feature 3 is also very bad. The class discriminability of feature 1 is in the middle. This can also be verified by using the discrimination criterion [34] as follows: (14) J = t r ( S w ) t r ( S b ) where tr denotes the trace of a matrix . Suppose that there are C classes and each class C i has N i samples. The degree of inner-class cohesion S w and the degree of inter-class separability S b are as follows [34] : (15) { S w = ∑ i = 1 C P ( C i ) E [ ( X − 1 N i ∑ X ∈ C i X ) ( X − 1 N i ∑ X ∈ C i X ) T ] S b = ∑ i = 1 C P ( C i ) ( 1 N i ∑ X ∈ C i X − M ) ( 1 N i ∑ X ∈ C i X − M ) T where X is a feature (vector) of a sample and (16) M = 1 C ∑ i = 1 C ( 1 N i ∑ X ∈ C i X ) is the mean of all the classes’ centroids . If J of some feature (or set of features) in Eq. (14) is smaller, then such a feature (or set of features) is more crisp and discriminable.

For the four dimensions of the artificially generated samples, there exists J ( 1 ) = 0.2666 , J ( 2 ) = 0.1336 , J ( 3 ) = 488.9156 , J ( 4 ) = 981.3525

It means that in terms of discriminability, feature 2 is the best; feature 4 is the worst; feature 3 is also very bad, and feature 1 is in the middle, which is accordant to the judgment based on the Gaussian parameters.

Now, we use different total uncertainty measures (including AM, AU , and our new TU I ) for the feature evaluation. Intuitively, the feature with smaller total uncertainty measure should be better (higher discriminability).

First, we generate BBA from each sample x q in the three-class artificial samples on different feature i ∈ {1, 2, 3} according to [35] (17) m x q i ( A j ) = | A j | − α / ( β − 1 ) d q j − 2 / ( β − 1 ) ∑ A k ≠ ∅ | A k | − α / ( β − 1 ) d q k − 2 / ( β − 1 ) + δ − 2 / ( β − 1 ) where parameters α = 1 , β = 2 as suggested in [34]. Here we give an illustrative example as in Fig. 10 .
Fig. 10

    Download : Download high-res image (262KB)
    Download : Download full-size image 

Fig. 10 . Illustration of BBA generation.

In Fig. 10 , three different colors represent three different classes. c 1 denotes the centroid of samples in class 1; c 1, 2 denotes the centroid of samples in class 1 and class 2; c 1, 2, 3 denotes the centroid of samples in classes 1, 2, and 3. Calculate the distance d between x q and those centroids of single classes and compound classes. Then according to Eq. (17) , the BBA can be generated.

Second, we calculate AU, AM , and our proposed TU I for all the generated BBAs (corresponding to each sample on different features). Then, calculate the average values of AU, AM and TU I for different features. The results are shown in Table 3 .

Table 3 . Average total uncertainty measures.
Measures (Ave)	Feature 1	Feature 2	Feature 3	Feature 4
AU 	1.4022	1.1968	1.5850	1.5850
AM 	1.1855	0.9860	1.5844	1.5847
TU I 	0.4496	0.3787	0.6218	0.6221

We consider the average total uncertainty measures as scores for different features. The feature with smaller score is better (with high discriminability)

As shown in Table 3 the feature evaluation based on the average TU I values is accordant to the results obtained using discrimination criterion. That is, feature 2 is the best; feature 4 is the worst; feature 3 is also very bad, and feature 1 is in the middle.

AM can also provide the correct feature evaluation result. Note that feature 3 is more ambiguous than feature 4. The difference of average TU I for features 3 and 4 is 0.0003; The difference of average AM for features 3 and 4 is also 0.0003. However, the value range of TU I is [0, 1], while the value range of AM is [0, log 2 3]. Therefore, our proposed TU I is more sensitive when measuring the ambiguity in different features, which agrees with the analysis in above examples.

The average AU values for both features 3 and 4 are equal. They are both the maximum value log 2 3 = 1.5850 . The reason is analyzed below.

According to the BBA generation approach used, because in features 3 and 4, all the centroids (7 centroids, 3 singleton classes, and 4 compound classes) are very close, all the distances between x q and those centroids are almost equal when generating BBAs for x q on features 3 and 4. Therefore, each focal element of the BBA generated for x q on features 3 and 4 has the mass value approximating to 1/7. According to all the BBAs generated, for feature 3, m ( A ) = ( 1 / 7 ) ± 0.010 ; for feature 4, m ( A ) = ( 1 / 7 ) ± 0.007 , A ⊆ { c 1 , c 2 , c 3 } . According to Eq. (10) , since AU is calculated based on the maximization of Shannon entropy given the constraints established using belief functions as 1 7 ≈ m ( { c 1 } ) ︸ B e l ( { c 1 } ) ≤ P ( c 1 ) ≤ m ( { c 1 } ) + m ( { c 1 , c 2 } ) + m ( { c 1 , c 3 } ) + m ( { c 1 , c 2 , c 3 } ) ≈ 4 7 ︸ P l ( { c 1 } ) 1 7 ≈ m ( { c 2 } ) ︸ B e l ( { c 2 } ) ≤ P ( c 2 ) ≤ m ( { c 2 } ) + m ( { c 1 , c 2 } ) + m ( { c 2 , c 3 } ) + m ( { c 1 , c 2 , c 3 } ) ≈ 4 7 ︸ P l ( { c 2 } ) 1 7 ≈ m ( { c 3 } ) ︸ B e l ( { c 3 } ) ≤ P ( c 3 ) ≤ m ( { c 3 } ) + m ( { c 1 , c 3 } ) + m ( { c 2 , c 3 } ) + m ( { c 1 , c 2 , c 3 } ) ≈ 4 7 ︸ P l ( { c 3 } ) P ( c 1 ) = P ( c 2 ) = P ( c 3 ) = 1 / 3 , which corresponds to the maximum Shannon entropy, always satisfies the constraints, so, the AU value is fixed to log 2 3 = 1.5850 . Based on AU, we cannot judge which one is better for features 3 and 4.

In summary, our proposed TU I can be well used in feature evaluation for pattern classification, and it performs better than AM and AU .
7. Conclusions

In this paper, a new total uncertainty measure based on the distance of belief intervals is proposed in the framework of belief functions theory. There is no switch between frameworks in the new measure. It is based on a new perspective that for a body of evidence, the farther it is from the most uncertain case, the less uncertainty it carries. It has been experimentally shown that our new measure can rationally represent the total uncertainty in BOEs. The new measure also has some desired properties and behaves more rational than traditional measures like AU and AM in some cases as shown in our experiments and simulations. Furthermore, our new measure can provide more rational results in practical applications such as the feature evaluation.

Till now, the theory of belief functions is still not so solid and needs further refining. The available works mainly focus on the uncertainty modeling and reasoning in belief functions theory and there have emerged many valuable results. However, the performance evaluation in belief functions theory is far from mature, which has become its bottle neck for the further development. In future work, we will focus on performance evaluation in the theory of belief functions and try to use our new total uncertainty measure to implement the theoretical evaluation and the application-based evaluation in the theory of belief functions.
Acknowledgments

This work was supported by the Grant for State Key Program for Basic Research of China (973) (No. 2013CB329405), National Natural Science Foundation (Nos. 61203222, 61573275 ), Foundation for Innovative Research Groups of the National Natural Science Foundation of China (No. 61221063), Science & Technology Project of Shaanxi Province (No.2013KJXX-46), Specialized Research Fund for the Doctoral Program of Higher Education (No. 20120201120036), and Fundamental Research Funds for the Central Universities (No. xjj2014122).
References

    [1]
    G. Shafer
    A Mathematical Theory of Evidence, Princeton University Press Princeton (1976)
    Google Scholar
    [2]
    G. Lin, J. Liang, Y. Qian
    An information fusion approach by combining multigranulation rough sets and evidence theory
    Inf. Sci., 314 (2015), pp. 184-199
    View PDF View article View in Scopus Google Scholar
    [3]
    G. Dong, G. Kuang
    Target recognition via information aggregation through Dempster–Shafer’s evidence theory
    IEEE Geosci. Remote Sens. Lett., 12 (6) (2015), pp. 1247-1251
    View in Scopus Google Scholar
    [4]
    Z.-g. Liu, Q. Pan, J. Dezert
    Evidential classifier for imprecise data based on belief functions
    Knowl. Based Syst., 52 (2013), pp. 246-257
    View PDF View article View in Scopus Google Scholar
    [5]
    Z.-g. Liu, Q. Pan, J. Dezert, G. Mercier
    Credal c-means clustering method based on belief functions
    Knowl. Based Syst., 74 (2015), pp. 119-132
    View PDF View article View in Scopus Google Scholar
    [6]
    O. Basir, X. Yuan
    Engine fault diagnosis based on multi-sensor information fusion using Dempster–Shafer evidence theory
    Inf. Fusion, 8 (4) (2007), pp. 379-386
    View PDF View article View in Scopus Google Scholar
    [7]
    D. Han, J. Dezert, J.-M. Tacnet, C. Han
    A fuzzy-cautious OWA approach with evidential reasoning
    Proceedings of the 15th International Conference on Information Fusion (FUSION), ISIF, Singapore (2012), pp. 278-285
    View in Scopus Google Scholar
    [8]
    R.R. Yager, N. Alajlan
    Dempster–Shafer belief structures for decision making under uncertainty
    Knowl. Based Syst., 80 (2015), pp. 58-66
    View PDF View article View in Scopus Google Scholar
    [9]
    G.J. Klir, B. Parviz
    A note on the measure of discord
    Proceedings of the Eighth International Conference on Uncertainty in Artificial Intelligence, Morgan Kaufmann Publishers Inc. (1992), pp. 138-141
    View PDF View article Google Scholar
    [10]
    D. Dubois, H. Prade
    A note on measures of specificity for fuzzy sets
    Int. J. Gen. Syst., 10 (4) (1985), pp. 279-283
    CrossRef View in Scopus Google Scholar
    [11]
    A.-L. Jousselme, C. Liu, D. Grenier, É. Bossé
    Measuring ambiguity in the evidence theory
    IEEE Trans. Syst. Man Cybern. Part A Syst. Hum., 36 (5) (2006), pp. 890-903
    View in Scopus Google Scholar
    [12]
    U. Höhle
    Entropy with respect to plausibility measures
    Proceedings of the 12th IEEE International Symposium on Multiple-Valued Logic (1982), pp. 167-169
    Google Scholar
    [13]
    R.V. Hartley
    Transmission of information
    Bell Syst. Tech. J., 7 (3) (1928), pp. 535-563
    CrossRef View in Scopus Google Scholar
    [14]
    R.R. Yager
    Entropy and specificity in a mathematical theory of evidence
    Int. J. Gen. Syst., 9 (4) (1983), pp. 249-260
    CrossRef View in Scopus Google Scholar
    [15]
    R. Körner, W. Näther
    On the specificity of evidences
    Fuzzy Sets Syst., 71 (2) (1995), pp. 183-196
    View PDF View article View in Scopus Google Scholar
    [16]
    D. Harmanec, G.J. Klir
    Measuring total uncertainty in Dempster–Shafer theory: a novel approach
    Int. J. Gen. Syst., 22 (4) (1994), pp. 405-419
    CrossRef View in Scopus Google Scholar
    [17]
    C.E. Shannon
    The mathematical theory of communication
    Bell Syst. Tech. J., 27 (1949), pp. 379-423,623–656
    Google Scholar
    [18]
    G. Klir, H.W. Lewis, III
    Remarks on “measuring ambiguity in the evidence theory”
    IEEE Trans. Syst. Man Cybern. Part A Syst. Hum., 38 (4) (2008), pp. 995-999
    CrossRef View in Scopus Google Scholar
    [19]
    J. Pearl
    Reasoning with belief functions: an analysis of compatibility
    Int. J. Approx. Reason., 4 (5) (1990), pp. 363-389
    View PDF View article View in Scopus Google Scholar
    [20]
    J. Dezert, A. Tchamova
    On the validity of Dempster’s fusion rule and its interpretation as a generalization of Bayesian fusion rule
    Int. J. Intell. Syst., 29 (3) (2014), pp. 223-252
    CrossRef View in Scopus Google Scholar
    [21]
    F. Smarandache, J. Dezert
    Advances and Applications of DSmT for Information Fusion-Collected Works, 3, American Research Press (2009)
    Google Scholar
    [22]
    J.F. Lemmer
    Confidence factors, empiricism and the Dempster–Shafer theory of evidence
    Proceedings of the First Conference on Uncertainty in Artificial Intelligence (UAI-85) (1985), pp. 160-176
    Google Scholar
    [23]
    L.A. Zadeh
    A simple view of the Dempster–Shafer theory of evidence and its implication for the rule of combination
    AI Mag., 7 (2) (1986), pp. 85-90
    View in Scopus Google Scholar
    [24]
    P. Wang
    A defect in Dempster–Shafer theory
    Proceedings of the Tenth International Conference on Uncertainty in Artificial Intelligence, Morgan Kaufmann Publishers Inc. (1994), pp. 560-566
    View PDF View article Google Scholar
    [25]
    A. Gelman
    The boxer, the wrestler, and the coin flip: a paradox of Bayesian inference, robust Bayes, and belief functions
    Am. Stat., 60 (2) (2005), pp. 146-150
    Google Scholar
    [26]
    G.J. Klir, A. Ramer
    Uncertainty in the Dempster–Shafer theory: a critical re-examination
    Int. J. Gen. Syst., 18 (2) (1990), pp. 155-166
    CrossRef View in Scopus Google Scholar
    [27]
    D. Dubois, H. Prade
    Properties of measures of information in evidence and possibility theories
    Fuzzy Sets Syst., 100 (1999), pp. 35-49
    View PDF View article View in Scopus Google Scholar
    [28]
    A. Ramer
    Uniqueness of information measure in the theory of evidence
    Fuzzy Sets Syst., 24 (2) (1987), pp. 183-196
    View PDF View article View in Scopus Google Scholar
    [29]
    J. Abellán, A. Masegosa
    Requirements for total uncertainty measures in Dempster–Shafer theory of evidence
    Int. J. Gen. Syst., 37 (6) (2008), pp. 733-747
    CrossRef View in Scopus Google Scholar
    [30]
    P. Smets, R. Kennes
    The transferable belief model
    Artif. Intell., 66 (2) (1994), pp. 191-234
    View PDF View article View in Scopus Google Scholar
    [31]
    A. Irpino, R. Verde
    Dynamic clustering of interval data using a Wasserstein-based distance
    Pattern Recognit. Lett., 29 (11) (2008), pp. 1648-1658
    View PDF View article View in Scopus Google Scholar
    [32]
    L. Tran, L. Duckstein
    Comparison of fuzzy numbers using a fuzzy distance measure
    Fuzzy, 130 (3) (2002), pp. 331-341
    View PDF View article View in Scopus Google Scholar
    [33]
    A. Papoulis, S.U. Pillai
    Probability, Random Variables, and Stochastic Processes (fourth), Tata McGraw-Hill Education (2002)
    Google Scholar
    [34]
    R.O. Duda, P.E. Hart, D.G. Stork
    Pattern Classification, John Wiley & Sons (2012)
    Google Scholar
    [35]
    M.-H. Masson, T. Denoeux
    ECM: An evidential version of the fuzzy c-means algorithm
    Pattern Recognit., 41 (4) (2008), pp. 1384-1397
    View PDF View article View in Scopus Google Scholar

Cited by (162)

    BF-QC: Belief functions on quantum circuits
    2023, Expert Systems with Applications
    Show abstract
    Dynamic multicriteria group decision-making method with automatic reliability and weight calculation
    2023, Information Sciences
    Show abstract
    A clustering based method to complete frame of discernment
    2023, Chinese Journal of Aeronautics
    Show abstract
    Permutation Jensen–Shannon divergence for Random Permutation Set
    2023, Engineering Applications of Artificial Intelligence
    Show abstract
    A numerical comparative study of uncertainty measures in the Dempster–Shafer evidence theory
    2023, Information Sciences
    Show abstract
    Novel moderate transformation of fuzzy membership function into basic belief assignment
    2023, Chinese Journal of Aeronautics
    Show abstract

View all citing articles on Scopus

1

    The distance d I ([ Bel ({ θ i }), Pl ({ θ i })], [0, 1]) reaches its maximum value when the belief interval is [0,0] or [1,1]. Therefore, the normalization factor is 1 / d I ( [ 0 , 0 ] , [ 0 , 1 ] ) = 1 / d I ( [ 1 , 1 ] , [ 0 , 1 ] ) = 3 .

View Abstract
Copyright © 2015 Published by Elsevier B.V.
Recommended articles

    Similarity measure for vague sets based on implication functions
    Knowledge-Based Systems, Volume 94, 2016, pp. 124-131
    Wenyi Zeng , …, Yundong Gu
    View PDF
    An intelligent quality-based approach to fusing multi-source probabilistic information
    Information Fusion, Volume 31, 2016, pp. 127-136
    Ronald R. Yager , Fred Petry
    View PDF
    40 years of Dempster–Shafer theory
    International Journal of Approximate Reasoning, Volume 79, 2016, pp. 1-6
    Thierry Denœux
    View PDF

Show 3 more articles
Article Metrics
Citations

    Citation Indexes: 155 

Captures

    Readers: 22 

plumX logo
View details
Elsevier logo with wordmark

    About ScienceDirect
    Remote access
    Shopping cart
    Advertise
    Contact and support
    Terms and conditions
    Privacy policy 

We use cookies to help provide and enhance our service and tailor content and ads. By continuing you agree to the use of cookies .

Copyright © 2023 Elsevier B.V. or its licensors or contributors. ScienceDirect® is a registered trademark of Elsevier B.V.

ScienceDirect® is a registered trademark of Elsevier B.V.
RELX group home page
↻
logo icon

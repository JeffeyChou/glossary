Information Sciences xxx (xxxx) xxx Contents lists available at ScienceDirect
Information Sciences
journal homepage: www.elsevier.com/locate/ins

A numerical comparative study of uncertainty measures in the Dempsterâ€“Shafer evidence theory
Michele Urbani âˆ—, Gaia Gasparini, Matteo Brunelli
Department of Industrial Engineering, University of Trento, via Sommarive 9, Trento, 38123, Italy

ARTICLE INFO
Keywords: Evidence theory Uncertainty measure Entropy Similarity

A B S T R A C T
We consider a wide range of measures of uncertainty that have been proposed within the Dempsterâ€“Shafer evidence theory. All these measures aim to quantify the uncertainty associated with a given basic probability assignment. As a preliminary step, we oï¬€er a study of the literature, which shows a recent resurgence of interest in the quantiï¬cation of uncertainty in the evidence theory. Then, we compare a number of uncertainty measures by means of numerical simulations and analyze their similarities and diï¬€erences using rank correlation coeï¬ƒcients, hierarchical clustering, and centrality analysis. The results show that uncertainty measures with similar formulations do not necessarily have similar numerical properties, and some original results are obtained. In particular, we demonstrate that numerical studies on uncertainty measures are necessary to obtain more insight and to enhance the interpretability of the values returned by the measures.

1. Introduction

Any expression of probability is a claim to a knowledge of the underlying issue which, by the nature of the problem, the speaker cannot have. In these circumstances, it may often make sense to describe the degree of uncertainty in non-probabilistic ways.
[John Kay and Mervyn King]

According to some widely accepted taxonomies [1, p. 53], uncertain phenomena can either be classiï¬ed as aleatoric or epistemic, depending on the nature of the underlying uncertain event. Aleatoric uncertainty refers to events with inherent randomness, while epistemic uncertainty refers to events for which there is a lack of knowledge. An example of epistemic uncertainty is in the exact time at which you ï¬rst saw this paper: there is no randomness, but only a lack of knowledge of the exact timing of the event. Whereas probability has been the main paradigm for dealing with aleatoric uncertainty, other theories have been proposed to represent uncertain phenomena of the epistemic type. Among these theories one can ï¬nd fuzzy sets theoryâ€”and its interpretation in terms of possibility theory [2]â€”and evidence theory, also called Dempsterâ€“Shafer theory, proposed by Dempster [3] as a formalization of lower and upper probabilities and then developed by Shafer [4]. In fact, evidence theory can be seen as a generalization of both probability and possibility theories [1] and great eï¬€ort has been made to make it operational and applicable in decision analysis.

* Corresponding author.
E-mail addresses: michele.urbani@unitn.it (M. Urbani), gaia.gasparini@unitn.it (G. Gasparini), matteo.brunelli@unitn.it (M. Brunelli).
https://doi.org/10.1016/j.ins.2023.119027 Received 11 October 2022; Received in revised form 17 April 2023; Accepted 24 April 2023
Available online 28 April 2023 0020-0255/Â© 2023 Elsevier Inc. All rights reserved.

Please cite this article as: Michele Urbani et al., Information Sciences, https://doi.org/10.1016/j.ins.2023.119027

M. Urbani, G. Gasparini and M. Brunelli

Information Sciences xxx (xxxx) xxx

If we turn our attention to the special case of probability theory, the uncertainty of probability distributions has generated an important stream of literature connected with the relationship between uncertainty and information. Clearly, the more uncertain a probability distribution is, the more information one can gain by learning the realization of the event. This insight is the basis for the interpretation of Shannon entropy [5], which is still the most widely known measure of uncertainty/information.
If we consider the more general framework of evidence theory, the last 40 yearsâ€”and especially the last 5â€”have witnessed the proposal of a wide number of uncertainty measures. However, it remains diï¬ƒcult to pin down a single measure that can be considered superior to all the others and, therefore, most of the proposed measures are still competitive when it comes to choosing among them in real-world applications. While some studies have attempted to ï¬nd an outstanding measure that satisï¬es a number of desirable theoretical properties, they have been inconclusive and therefore, at present, none of the proposed measures should be considered superior. Other studies have compared measures with respect to speciï¬c case studies, so that some of their properties, such as monotonicity, can be veriï¬ed empirically. However, such studies cannot oï¬€er a broad overview of the similarities and diï¬€erences between uncertainty measures.
Let us note that the matter of the fair quantiï¬cation of uncertainty within evidence theory is far from being a mere theoretical exercise, as the choice of uncertainty measure can have repercussions for real-world applications. Furthermore, the use of uncertainty measures has gone beyond the mere quantiï¬cation of uncertainty, as shown by, for instance, their recent application in the evaluation of approximations of conjoint belief distributions [6].
The scope of this paper is to oï¬€er a presentation of uncertainty measures, in conjunction with a recap of their mathematical properties and a brief historical perspective of their development. However, since studies of the properties of such measures have already been presented in the literature, the main goal of this paper is to present the results of a numerical study that highlights possible similarities, diï¬€erences, and mutual support between uncertainty measures in the evidence theory. So far, numerical comparative studies have been performed in some speciï¬c instances to show that some proposed measures, unlike some old ones, do satisfy some desirable properties.
For example, Wen et al. [7] considered only 9 representative mass assignments to compare 4 uncertainty measures and Pan et al. [8] veriï¬ed the satisfaction of the property of monotonicity by applying 5 uncertainty measures to a family of 14 mass assignments for which, ceteris paribus, the cardinality of an element of the frame of discernment is increasing. A similar analysis of the monotonicity of 9 measures was oï¬€ered by Wang et al. [9].
We conclude that the scope of these analyses remains limited and they cannot be considered full-ï¬‚edged comparative studies of uncertainty measures. Hopefully, in addition to the existing literature, a more comprehensive numerical study will help choose among the many uncertainty measures.
The paper is organized as follows. Section 2 presents the basics of evidence theory and a brief introduction to the concept of entropy in probability theory. Section 3 is an exposition of a number of uncertainty measures that can be used in the evidence theory, with an eye on their formal properties and their historical development. Section 4 presents the methodological tools used in the analysis, and the results. Finally, in Section 5 we draw some conclusions.

2. Evidence theory and uncertainty

Let ğ‘‹ = {ğ‘¥1, ğ‘¥2, â€¦ , ğ‘¥ğ‘›} be a non-empty set containing ğ‘› exhaustive and mutually exclusive elements; this set is called the frame of discernment (FOD). The power set of ğ‘‹ is denoted as 2ğ‘‹ . A basic probability assignment (BPA), or mass assignment, is a function

ğ‘š âˆ¶ 2ğ‘‹ â†’ [0, 1]

(1)

that satisï¬es

âˆ‘

ğ‘š(ğ´) = 1 and ğ‘š(âˆ…) = 0,

(2)

ğ´âˆˆ2ğ‘‹

where ğ´ âŠ† ğ‘‹ is called a focal element if ğ‘š(ğ´) > 0. The set of all the focal elements is denoted as îˆ² = {ğ´ âŠ† ğ‘‹|ğ‘š(ğ´) > 0}. The set of focal elements together with their masses is called the body of evidence (BOE). Indeed, the BPA can be seen as a generalization of the common assignments of probabilities on singletons, which is now done on all the elements of 2ğ‘‹ . In fact, the BPA assigns a value between 0 and 1 to every element of the power set, so that ğ‘š(ğ´) can be interpreted as the normalized amount of evidence that a given event belongs to ğ´.
Two relevant measures can be associated with a BPA. First, given a BPA, the belief of ğ´ is deï¬ned as the sum of all the masses of the subsets of ğ´ (and of ğ´ itself),

âˆ‘

Bel(ğ´) = ğ‘š(ğµ), âˆ€ğ´ âˆˆ 2ğ‘‹ ,

(3)

ğµâŠ†ğ´

and is a superadditive measure. This measure can be interpreted as the quantiï¬cation of the level of conï¬dence in knowing that the event is within ğ´: through the sum of the masses, the belief measures the strength of the evidence in favor of the presence of the element in ğ´ or in a subset thereof. Second, the plausibility of ğ´ is the sum of the masses of all the subsets that intersect ğ´,

âˆ‘

Pl(ğ´) =

ğ‘š(ğµ),

âˆ€ğ´ âˆˆ 2ğ‘‹ .

(4)

ğµâˆ©ğ´â‰ âˆ…

2

M. Urbani, G. Gasparini and M. Brunelli

Information Sciences xxx (xxxx) xxx

Unlike belief, plausibility is a subadditive measure of the strength of the evidence that does not contradict the presence of the event in ğ´.
The two measures Bel(ğ´) and Pl(ğ´) represent, respectively, the lower and the upper bounds of the probability of ğ´, that is, âˆƒ Pr such that

Bel(ğ´) â‰¤ Pr(ğ´) â‰¤ Pl(ğ´), âˆ€ğ´ âŠ† ğ‘‹.

(5)

The set of probability functions compatible with Eq. (5) is a credal set, that is, a convex set of probability distributions. Hereafter, we denote by îˆ¼(ğ‘š) the credal set induced by ğ‘š by means of the condition in Eq. (5). Note that (i) this also highlights the connection between evidence theory and the theory of imprecise probabilities and (ii) when the mass assignment involves only {ğ‘¥ğ‘–}, we have Bel(ğ´) = Pr(ğ´) = Pl(ğ´), âˆ€ğ´ âŠ† ğ‘‹, which casts probability as a special case of the evidence theory.
Another important concept is Shannon entropy. Within the framework of probability theory, Shannon [5] introduced the concept of entropy as a measure of the amount of information associated with knowing the outcome of an uncertain event. Formally, Shannon entropy is deï¬ned as

âˆ‘ğ‘›

ğ–§ğ‘ (ğ‘) = âˆ’ ğ‘(ğ‘¥ğ‘–) log2 ğ‘(ğ‘¥ğ‘–),

(6)

ğ‘–=1

where ğ‘(ğ‘¥ğ‘–) is the probability of ğ‘¥ğ‘– âˆˆ ğ‘‹. Indeed, it attains its maximum when the probability is uniform and the uncertainty is maximum. Similarly, in set theory, set uncertainty depends on the cardinality of the set and is usually measured by means of the Hartley entropy, according to which the uncertainty of a set ğ´ is log2 |ğ´|.
According to Ayyub and Klir [1, Ch. 4], a suï¬ƒciently general mathematical representation of uncertainty, as the evidence theory, should be able to accommodate two types of uncertainty: conï¬‚ict and non-speciï¬city. In fact, in the evidence theory, diï¬€erent types of uncertainties coexist within the BPA and therefore it is now accepted that, when we want to measure the (total) uncertainty of the assignment ğ‘š, we ought to consider both facets of uncertainty.
The situation is made even more complex by the fact that conï¬‚ict and non-speciï¬city have multiple interpretations. For example, non-speciï¬city, which should measure the divergence of a BPA from being Bayesian (i.e., from having all the evidence assigned to singletons), has at least three interpretations [10]: (i) one in light of Hartley entropy, (ii) one related to the width of the socalled belief intervals [Bel(ğ´), Pl(ğ´)], and (iii) one connected to the information volume of the credal set îˆ¼(ğ‘š). Further complexities emerge when one considers conï¬‚ict. In fact, axiomatic studies such as the one by Bronevich and Lepskiy [11] explain that there are multiple ways to quantify the conï¬‚ict in ğ‘š that â€œdo not coincide with the Shannon entropy on probability measures.â€ This richness of interpretations has provided fertile ground for the development of uncertainty measures.

3. Uncertainty measures in evidence theory

Several measures of uncertainty for basic probability assignments have been proposed in the evidence theory. Those studied in this paper are listed and commented on here, using the names of their proponents. Unless otherwise stated, in the following deï¬nitions, we will assume ğ´ and ğµ to be subsets of the FOD, that is, ğ´, ğµ âŠ† ğ‘‹, and we use |ğ´| to denote the cardinality of set ğ´. In addition, for simplicity, functions of singletons are written without curly brackets, for example, Pl({ğ‘¥1}) = Pl(ğ‘¥1). We shall see that the oldest measures of uncertainty are, at times, simplistic and cannot fully capture all facets of uncertainty.

HÃ¶hle According to Klir and Ramer [12], the investigation of entropy in the evidence theory started in the 1980s, with the ï¬rst measure,
proposed by HÃ¶hle [13], deï¬ned as

âˆ‘

ğ–§ğ‘‚(ğ‘š) = âˆ’ ğ‘š(ğ´) log2 Bel(ğ´).

(7)

ğ´âˆˆîˆ²

This attains its minimum if and only if the BPA is deterministic, that is, there exists ğ´ âŠ† ğ‘‹ such that ğ‘š(ğ´) = 1. In the literature, this measure is often called confusion.

Yager Similarly to HÃ¶hle, Yager [14] proposed a measure of uncertainty starting again from the deï¬nition of Shannon entropy. Like the
preceding one, this one by Yager,

âˆ‘

ğ–§ğ‘¦(ğ‘š) = âˆ’ ğ‘š(ğ´) log2 Pl(ğ´),

(8)

ğ´âˆˆîˆ²

aimed at capturing conï¬‚ict. In the literature, this measure is often called dissonance.

Smets Smets [15] proposed a conï¬‚ict measure with the use of the commonality function. The entropy, in this case, measures the
information content of a BOE, and its formulation is
3

M. Urbani, G. Gasparini and M. Brunelli

Information Sciences xxx (xxxx) xxx

âˆ‘

ğ–§ğ‘¡(ğ‘š) = âˆ’ ğ‘(ğ´) log2 ğ‘„(ğ´),

(9)

ğ´âˆˆîˆ²

âˆ‘ where ğ‘„(ğ´) = ğµ|ğ´âŠ†ğµ ğ‘š(ğµ) is the so-called commonality function already deï¬ned by Shafer [4]. Furthermore, we set ğ‘(ğ´) = 1, which

is, according to Smets [15, p. 37], the â€œmost natural choice.â€

Nguyen The measure proposed by Nguyen [16], deï¬ned as

âˆ‘

ğ–§ğ‘›(ğ‘š) = âˆ’ ğ‘š(ğ´) log2 ğ‘š(ğ´),

(10)

ğ´âˆˆîˆ²

is the most straightforward extension of Shannon entropy.

Dubois and Prade It can be observed that all the previously recalled uncertainty measures do not consider the cardinality of sets ğ´. To give a
concrete example, if there is ğ´ âŠ† ğ‘‹ with ğ‘š(ğ´) = 1, they all reach their minimum, regardless of whether ğ´ is a singleton or the FOD ğ‘‹ itself. Nonetheless, it is intuitive to consider the former case as less â€œuncertainâ€ than the latter. Dubois and Prade [17] introduced the ï¬rst measure of non-speciï¬city, deï¬ned as a weighted average of Hartley entropies with respect to each focal element ğ´ âˆˆ îˆ² ,

âˆ‘

ğ–§ğ‘‘ (ğ‘š) = ğ‘š(ğ´) log2 (|ğ´|) .

(11)

ğ´âˆˆîˆ²

Klir and Ramer

The measure presented by Klir and Ramer [12] was introduced to improve the measures ğ–§ğ‘‚ and ğ–§ğ‘¦, and is deï¬ned as

(

)

âˆ‘ ğ–§ğ‘˜(ğ‘š) = âˆ’ ğ‘š(ğ´) log2
ğ´âˆˆîˆ²

âˆ‘
ğµâˆˆîˆ²

ğ‘š(ğµ)

|ğ´ âˆ© ğµ| |ğµ|

.

(12)

Klir and Parviz

An improvement of the previous measure was studied by Klir and Parviz [18]. They proposed the formulation

(

)

âˆ‘ ğ–§ğ‘(ğ‘š) = âˆ’ ğ‘š(ğ´) log2
ğ´âˆˆîˆ²

âˆ‘
ğµâˆˆîˆ²

ğ‘š(ğµ)

|ğ´ âˆ© ğµ| |ğ´|

.

(13)

Let us note that Klir and Ramer [12] and Klir and Parviz [18] also deï¬ned two measures of total uncertainty that are not usually cited in the literature.

Lamata and Moral The uncertainty measures considered until now have the shortcoming of considering only some facets of uncertainty. Lamata
and Moral [19] paved the way for more complex approaches when they deï¬ned a global measure to account for the two aspects of uncertainty. In a nutshell, Lamata and Moral [19] proposed summing the uncertainty measures of Yager [14] and Dubois and Prade [17]:

ğ–§ğ‘¦(ğ‘š)+ğ–§ğ‘‘ (ğ‘š)

ğ–§ğ‘™(ğ‘š) = ââˆ’âğ´ââˆ‘ ââˆˆâââîˆ²âââğ‘šâââ(âğ´âââ)ââ log2âââ(ââââPââ|lâğ´â(âğ´â|ââ)âââ) .

(14)

Pal et al. Pal et al. [20] deï¬ned a new measure of total uncertainty,

ğ–§ğ‘(ğ‘š) = ââˆ’âğ´ââˆ‘ ââˆˆâââîˆ²âââğ‘šââğ–§â(âğ‘‘ğ´ââ(âğ‘šâ)â )l+oğ–§gâğ‘›2â(â(ğ‘šâââ)âğ‘šââ|âğ´â(âğ´ââ|â)âââ) .

(15)

Even in this case, the measure can be decomposed into two separate measures of conï¬‚ict and non-speciï¬city.

Harmanec and Klir

Harmanec and Klir [21] considered the credal set îˆ¼(ğ‘š) and suggested taking the probability distribution ğ‘ âˆˆ îˆ¼(ğ‘š) that maximizes

Shannon entropy. Namely, they solved the following optimization problem:

{ âˆ‘ğ‘›

}

ğ– ğ–´(ğ‘š) = max
ğ‘âˆˆîˆ¼ (ğ‘š)

âˆ’ ğ‘(ğ‘¥ğ‘–) log2 ğ‘(ğ‘¥ğ‘–)
ğ‘–=1

,

(16)

4

M. Urbani, G. Gasparini and M. Brunelli

Information Sciences xxx (xxxx) xxx

where ğ– ğ–´ is the aggregate uncertainty. While being a potentially diï¬ƒcult optimization problem, some algorithmic procedures have been proposed to eï¬ƒciently solve it and we adopted the one proposed by Huynh and Nakamori [22].

George and Pal

George and Pal [23] deï¬ned discord as the average of the conï¬‚ict between each pair of pieces of evidence:

ğ–³ğ–¢(ğ‘š)

=

âˆ‘

ğ‘š(ğ´)

âˆ‘

( ğ‘š(ğµ) 1 âˆ’

) |ğ´ âˆ© ğµ| .

(17)

ğ´âˆˆîˆ²

ğµâˆˆîˆ²

|ğ´ âˆª ğµ|

Jousselme et al. Jousselme et al. [24] considered a set of reasonable properties and proposed another measure,

âˆ‘ğ‘›

ğ– ğ–¬(ğ‘š) = âˆ’ Bet(ğ‘¥ğ‘–) log2 Bet(ğ‘¥ğ‘–),

(18)

ğ‘–=1

where ğ– ğ–¬ is the ambiguity measure, and Bet(ğ‘¥ğ‘–) is the pignistic transformation,

Bet(ğ‘¥ğ‘–)

=

âˆ‘
ğ´|ğ‘¥ğ‘– âˆˆğ´

ğ‘š(ğ´) |ğ´|

âˆ€ğ‘– = 1, â€¦ , ğ‘›,

whose goal is to uniformly distribute the mass function of every focal element ğ´ to its elements ğ‘¥ğ‘– âˆˆ ğ´.

Yang and Han Yang and Han [25] considered the belief interval, [Bel(ğ´), Pl(ğ´)], as representative of the uncertainty, and took into consideration
the distance between the belief interval of a focal element and the most uncertain case [0, 1]. Their uncertainty measure is

ğ–³ğ–´ğ¼

(ğ‘š)

=

1

âˆ’

1 ğ‘›

âˆš 3

âˆ‘ğ‘›
ğ‘–=1

ğ‘‘ğ¼ ([Bel(ğ‘¥ğ‘–),

Pl(ğ‘¥ğ‘–)], [0,

1]),

(19)

âˆš

where 3 is the normalization factor and

ğ‘‘ğ¼

(

)

[Bel(ğ‘¥ğ‘–), Pl(ğ‘¥ğ‘–)], [0, 1]

=

âˆš[ Bel(ğ‘¥ğ‘–) + 2

Pl(ğ‘¥ğ‘–)

âˆ’

0

+ 2

1 ]2

+

1 3

[ Pl(ğ‘¥ğ‘–)

âˆ’ Bel(ğ‘¥ğ‘–) 2

âˆ’

1

âˆ’ 2

0 ]2.

Deng and Wang

In an attempt to improve ğ–³ğ–´ğ¼ , Deng and Wang [26] used the Hellinger distance to measure the distance between intervals and

proposed a new measure, which eventually collapses into

âˆ‘ğ‘› ( âˆš(âˆš

)2 ( âˆš

)2)

ğ–£ğ–´(ğ‘š) = 1 âˆ’

Bel(ğ‘¥ğ‘–) âˆ’ 0 + 1 âˆ’ Pl(ğ‘¥ğ‘–) .

(20)

ğ‘–=1

Li et al.

Li et al. [27] used the Euclidean distance between intervals, and deï¬ned

([

]

)âˆš

ğ‘‘ğ¸ Bel(ğ‘¥ğ‘–), Pl(ğ‘¥ğ‘–) , [0, 1] = [Bel(ğ‘¥ğ‘–) âˆ’ 0]2 + [Pl(ğ‘¥ğ‘–) âˆ’ 1]2.

Then, a transformation of this distance was considered and summed with respect to all the elements of the FOD so that it can be

interpreted as a measure of uncertainty,

ğ–³ğ–´(ğ‘š)

=

âˆ‘ğ‘›
ğ‘–=1

(

1

2 + ğ‘‘ğ¸

) âˆ’1 .

(21)

Deng et al. [28] also employed the Euclidean distance to propose a similar uncertainty measure.

Wang and Song Wang and Song [29] considered the relationship between all central values,

Bel(ğ‘¥ğ‘–) + Pl(ğ‘¥ğ‘–) , 2

as a measure of conï¬‚ict, and Pl(ğ‘¥ğ‘–) âˆ’ Bel(ğ‘¥ğ‘–) as a measure of non-speciï¬city. The authors used the Shannon entropy to deï¬ne conï¬‚ict and included the non-speciï¬city term in the deï¬nition,

ğ–²ğ–´(ğ‘š)

=

âˆ‘ğ‘›

[ âˆ’

Bel(ğ‘¥ğ‘–

)

+

ğ‘–=1

2

Pl(ğ‘¥ğ‘–)

log2

Bel(ğ‘¥ğ‘–) + 2

Pl(ğ‘¥ğ‘–)

+

Pl(ğ‘¥ğ‘–)

âˆ’ Bel(ğ‘¥ğ‘–) ] . 2

(22)

5

M. Urbani, G. Gasparini and M. Brunelli

Information Sciences xxx (xxxx) xxx

Deng

Deng [30] considered the measure proposed by Pal et al. [20] and modiï¬ed it to give more importance to the relation between

|ğ´| and the increase of non-speciï¬city [31]:

ğ–§ğ‘”

(ğ‘š)

=

âˆ’

âˆ‘
ğ´âˆˆîˆ²

ğ‘š(ğ´)

log2

(

ğ‘š(ğ´) 2|ğ´| âˆ’ 1

)

.

(23)

Formal properties of this measure have been critically inspected by AbellÃ¡n [31], Moral-GarcÃ­a and AbellÃ¡n [32].

Pan and Deng

Pan and Deng [33] also used the central values of belief intervals proposed by Wang and Song [29], mixing this approach with the scaling factor proposed by Deng [30]. The resulting measure of uncertainty is1

ğ–§ğ‘ğ‘’ğ‘™ (ğ‘š)

=

âˆ‘ âˆ’
ğ´âˆˆîˆ²

Bel(ğ´) + 2

Pl(ğ´)

log2

Bel(ğ´) + Pl(ğ´) 2(2|ğ´| âˆ’ 1)

.

(24)

JirouÅ¡ek and Shenoy

JirouÅ¡ek and Shenoy [6] proposed the measure

()

ğ–§ğ‘—

(ğ‘š)

=

ğ–§ğ‘  PlT
âğ‘¥âˆ‘ ğ‘–âˆˆâââğ‘‹âââPââlââTââ(ââğ‘¥ââğ‘–â)âââ log2ââ(ââââPââlââTâ1â(âğ‘¥âââğ‘–â)âââ)

+

ââˆ‘ââââââââââğ–§â ğ‘‘ (ğ‘š)âââââââââââ ğ‘š(ğ´) log2(|ğ´|)
ğ´âˆˆîˆ²

.

(25)

It may appear similar to the Jousselme et al. [24] ambiguity measure but, as argued by JirouÅ¡ek and Shenoy [6], the pignistic transformation used by Jousselme et al. [24] cannot satisfy one of the deï¬ned requirements. The plausibility transformation

PlT(ğ‘¥ğ‘–) = âˆ‘ğ‘›ğ‘—P=1l(Pğ‘¥lğ‘–()ğ‘¥ğ‘— ) âˆ€ğ‘¥ğ‘– âˆˆ ğ‘‹

is another method to transform a belief function model into a corresponding probability function model.

Zhou et al.

Zhou et al. [34] deï¬ned entropy including, for the ï¬rst time, the cardinality of the FOD. Compared to Deng entropy, in this

measure,

ğ–¤ğ‘€

ğ‘‘

(ğ‘š)

=

âˆ’

âˆ‘
ğ´âŠ†ğ‘‹

ğ‘š(ğ´)

log2

(

ğ‘š(ğ´) 2|ğ´| âˆ’ 1

ğ‘’

|ğ´|âˆ’1 |ğ‘‹|

)

,

(26)

there

is

an

additional

term:

the

factor

|ğ´|âˆ’1 |ğ‘‹|

normalizes

the

cardinality

of

every

focal

element

to

the

FOD.

Cui et al. Other authors have started by including |ğ‘‹| in their deï¬nition and also introduced the element of intersection between focal
elements. Cui et al. [35] deï¬ned a novel uncertainty measure as follows:

â›

â›

ââ

ğ–¤(ğ‘š)

=

âˆ’

âˆ‘
ğ´âŠ†ğ‘‹

ğ‘š(ğ´)

log2

âœ âœ âœâ

ğ‘š(ğ´) 2|ğ´| âˆ’ 1

exp

âœâˆ‘ âœ âœâğµğµâˆˆâ‰ îˆ²ğ´

|ğ´ âˆ© ğµ| 2|ğ‘‹| âˆ’ 1

âŸâŸ âŸâŸ âŸâ âŸâ 

.

(27)

If there are no intersections, the equation reduces to Deng [30] entropy.

Yan and Deng

Yan and Deng [36] modiï¬ed the deï¬nition of Zhou et al. [34] by combining it with the belief measure and by considering, instead

of |ğ‘‹|, the number of singletons with Pl > 0 indicated with |ğ‘†|:

ğ–§ğ‘€

ğ‘‘

(ğ‘š)

=

âˆ’

âˆ‘
ğ´âŠ†ğ‘‹

ğ‘š(ğ´)

log2

(

ğ‘š(ğ´) + Bel(ğ´) 2(2|ğ´| âˆ’ 1)

ğ‘’

|ğ´|âˆ’1 |ğ‘†|

)

.

(28)

Qin et al. Other authors have also had the idea of taking into account the cardinality |ğ‘‹| of the FOD. Qin et al. [37] proposed a total
uncertainty measure

1 Let us note that, in the original formulation by Pan and Deng, this measure was deï¬ned as a sum over all ğ´ âŠ† ğ‘‹, but in the same paper the illustrative examples considered the sum over all ğ´ âˆˆ îˆ² . We consider this latter formulation, which ï¬ts the numerical examples presented in the original paper [33].
6

M. Urbani, G. Gasparini and M. Brunelli

ğ–§ğ‘ (ğ‘š)

=

âˆ‘
ğ´âˆˆîˆ²

|ğ´| |ğ‘‹|

ğ‘š(ğ´)

log2

(|ğ´|)

+

âˆ‘
ğ´âˆˆîˆ²

ğ‘š(ğ´) log2

()

1 ğ‘š(ğ´)

,

Information Sciences xxx (xxxx) xxx
(29)

where the entropy of Nguyen is used to measure the conï¬‚ict and the entropy of Dubois and Prade measures non-speciï¬city. The latter is scaled by the relative weight |ğ´|âˆ•|ğ‘‹|.

Li and Pan Unlike the preceding authors, Li and Pan [38] modiï¬ed the non-speciï¬city term, which is the uncertainty measure by Dubois and
Prade [17] multiplied by |ğ‘‹|,

ğ–§ğµ&ğ¹ (ğ‘š)

=

âˆ‘
ğ´âˆˆîˆ²

ğ‘š(ğ´) log2

|ğ´||ğ‘‹| . ğ‘š(ğ´)

(30)

Zhou and Deng Zhou and Deng [39] proposed a measure of entropy based on a probability transformation that takes inspiration from the theory
of fractals. More speciï¬cally, the fractal-based (ğ¹ ğµ) entropy measure is

âˆ‘ ğ–¤ğ¹ ğµ = âˆ’ ğ‘šğ¹ (ğ´) log2 ğ‘šğ¹ (ğ´)
ğ´âˆˆîˆ²

(31)

where ğ‘šğ¹ is deï¬ned as follows:

ğ‘šğ¹

(ğ´)

=

âˆ‘
ğµ|ğ´âŠ†ğµ

ğ‘š(ğµ) 2|ğµ| âˆ’ 1

.

Other measures While the description of uncertainty measures has been, so far, quite extensive, we remark that some measures have not been
analyzed in detail. For example, the formulations of the measures proposed by Wen et al. [7] and Zhao et al. [40] are extremely technical, while the two measures proposed by Zhang et al. [41] and Wang et al. [9] are parametric, and any comparison of them with other measures would be limited by having to ï¬x a value for the parameters.

3.1. Mathematical properties of uncertainty measures

Although the focus of this paper is more on their numerical aspects, we consider it useful to present a brief summary of formal aspects of uncertainty measures. Over the years, a wide range of studies have analyzed the formal propertiesâ€”in the form of desirable properties or axiomsâ€”of uncertainty measures. Recounting all of them would be beyond the scope of this paper, but it is safe to say that the following ï¬ve have gained prominence:

1. Probabilistic consistency: If ğ‘š takes the form of a probability distribution function, meaning that all focal elements are singletons, then the measure must be equal to the Shannon entropy.
2. Set consistency: When ğ‘š focuses on a single set ğ´ (meaning that ğ‘š(ğ´) = 1 for one particular set ğ´), then the measure of uncertainty must collapse into the Hartley entropy.
3. Subadditivity: When ğ‘š is a joint BPA on the Cartesian product ğ‘‹ Ã— ğ‘Œ and ğ‘šğ‘‹ and ğ‘šğ‘Œ are the respective associated marginal BPAs, then an uncertainty measure ğ–§ is subadditive if and only if
ğ–§(ğ‘š) â‰¤ ğ–§(ğ‘šğ‘‹ ) + ğ–§(ğ‘šğ‘Œ ).
4. Additivity: When ğ‘š is a joint BPA on ğ‘‹ Ã— ğ‘Œ and ğ‘šğ‘‹ and ğ‘šğ‘Œ are the respective associated marginal BPAs, then if these marginal BPAs are non-interactive, an uncertainty measure ğ–§ is additive if and only if
ğ–§(ğ‘š) = ğ–§(ğ‘šğ‘‹ ) + ğ–§(ğ‘šğ‘Œ ).
5. Monotonicity: Consider any two BPAs ğ‘š1 and ğ‘š2 deï¬ned on the FOD ğ‘‹ such that Bel2(ğ´) â‰¤ Bel1(ğ´) âˆ€ğ´ âŠ† ğ‘‹, then ğ–§ is monotone if and only if
ğ–§(ğ‘š1) â‰¤ ğ–§(ğ‘š2).
Other properties, for instance, consistency with Dempsterâ€“Shafer semantics, range, non-negativity, and maximum entropy, were discussed by JirouÅ¡ek and Shenoy [6]. Table 1 presents a summary of the uncertainty measures reported in this section and whether they satisfy the above ï¬ve properties. We also attempt a classiï¬cation according to the type of uncertainty that is captured by each measure and the paradigm on which the measure is based.
As recently conï¬rmed by Moral-GarcÃ­a and AbellÃ¡n [46], the uncertainty measure of Harmanec and Klir is the only one proposed in the literature that satisï¬es all the above-mentioned properties. However, it is quite complex to implement in practice. It can be seen from Table 1 that a full analysis has not been carried out for the most recent measures of uncertainty. In some cases, the satisfaction of some properties has been veriï¬ed using examples and therefore more work is needed toward a formal proof. The

7

M. Urbani, G. Gasparini and M. Brunelli

Information Sciences xxx (xxxx) xxx

Table 1 Measures of uncertainty and their properties: a review of the literature. Y: the property has been formally established, N: the property is not satisï¬ed, ?: the property was not studied or evidence seems inconclusive. The column â€œSourceâ€ lists the publications in which the satisfaction of the properties is discussed. In the column â€œContent,â€ measures are labeled according to the category they belong to: total uncertainty (TU), discord (D), or non-speciï¬city (NS). The last column indicates whether the measure is based on the entropy formulation (EB) and/or uncertainty intervals (IB).

Eq. Proponent(s)

P. cons. S. cons. Add. Subadd. Monot. Source Type Content

(7) HÃ¶hle

Y

(8) Yager

Y

(9) Smets

N

(10) Nguyen

Y

(11) Dubois and Prade

N

(12) Klir and Ramer

Y

(13) Klir and Parviz

Y

(14) Lamata and Moral

Y

(15) Pal et al.

Y

(16) Harmanec and Klir

Y

(17) George and Pal

Y

(18) Jousselme et al.

Y

(19) Yang and Han

N

(20) Deng and Wang

N

(21) Li et al.

N

(22) Wang and Song

Y

(23) Deng

Y

(24) Pan and Deng

Y

(25) JirouÅ¡ek and Shenoy Y

(26) Zhou et al.

N

(27) Cui et al.

N

(28) Yan and Deng

Y

(29) Qin et al.

Y

(30) Li and Pan

Y

(31) Zhou and Deng

Y

N

Y

N

N

Y

N

N

Y

N

N

Y

N

Y

Y

Y

Y

Y

N

Y

Y

N

Y

Y

N

Y

Y

N

Y

Y

Y

Y

Y

N

Y

Y

N

N

N

N

N

?

?

N

N

N

Y

?

?

N

N

N

?

N

N

N

Y

N

N

N

N

N

N

N

Y

N

N

N

N

?

?

N

N

N

Y

Y

N

[8,37] D

EB

N

[8,37] D

EB

N

[8]

D

EB

N

[8,37] D

EB

Y

[8,37] NS

EB

Y

[8,37] TU

EB

Y

[8,37] TU

EB

Y

[6]

TU

EB

Y

[8]

TU

EB

Y

[8,31] TU

EB

N

[42,8] TU

Y

[8,43] TU

EB

N

[44,45] TU

IB

Y

[26]

TU

IB

?

[27]

TU

IB

N

[29,44] TU

EB, IB

N

[31]

TU

EB

Y

[33,8] TU

EB

Y

[6,37] TU

EB

N

[32]

TU

EB

N

[32]

TU

EB

?

[36]

TU

EB

?

[37]

TU

EB

?

[38]

TU

EB

?

[39]

TU

EB

relative importance of these properties is, however, still subject to debate. For example, Deng [44] stated that â€œmonotonicity is one of the most important properties.â€ Meanwhile, Yang and Han [25] have argued that properties like additivity and subadditivity are â€œmeaninglessâ€ for their uncertainty measure, since it is not a direct extension of probability theory but an ad hoc proposal for evidence theory. Deng and Wang [26] stated that the â€œevidence theory framework is diï¬€erent from the probability theory framework and the classical set theory,â€ meaning that substantially diï¬€erent properties should be required. They also argued that additivity and subadditivity are relevant only if the uncertainty measure is applied to the Cartesian product ğ‘‹ Ã— ğ‘Œ and irrelevant otherwise. For this reason, some alternative axiomatic frameworks have been promoted, for example in [44].
In addition to the above-mentioned formal properties, some desiderata have been proposed. In contrast to formal properties, they are often subjective and their fulï¬llment is a matter of degree. Moral-GarcÃ­a and AbellÃ¡n [46] proposed the following four desiderata:
â€¢ The calculation of the uncertainty measure should not be excessively complex. â€¢ It should be possible to decompose the uncertainty measure into its conï¬‚ict and non-speciï¬city parts. â€¢ The measure should be sensitive to changes in ğ‘š. â€¢ The measure should be applicable to frameworks more general than evidence theory.
For an updated inquiry into mathematical properties and desiderata of uncertainty measures, one can refer to Moral-GarcÃ­a and AbellÃ¡n [46], in which a deeper analysis is presented that makes a distinction between BPA- and interval-based uncertainty measures.
3.2. A brief historical perspective
Fig. 1 oï¬€ers a snapshot of the development of uncertainty measures over time and, quite remarkably, seems to divide the last 40 years into four distinct periods. The ï¬rst period (1982â€“1987) saw the inception of the most basic measures, capable of capturing only some facets of the total uncertainty. In the second period (1988â€“1995), starting with the measure proposed by Lamata and Moral [19], eï¬€orts were redirected toward (i) the formulation of more holistic measures that can capture the total uncertainty of mass assignment and (ii) their formal analysis. The third period (1996â€“2015) is the longest and saw few new proposals. In the fourth and current period (2016â€“today) we are witnessing a strong resurgence of uncertainty measures. In particular, new measures are often inspired by existing ones and justiï¬ed by showing better performance with respect to some speciï¬c examples. Moreover, in recent years, as noted with some concern by Dezert and Tchamova [47], a weaker emphasis has been placed on the analysis of formal properties of these measures, possibly in light of the impossibility of ï¬nding a measure that can satisfy all properties and desiderata.
8

M. Urbani, G. Gasparini and M. Brunelli

Information Sciences xxx (xxxx) xxx

Fig. 1. Timeline of the seminal papers for various uncertainty measures.
4. Methodology and results
As already speciï¬ed, we are interested in studying the relations between diï¬€erent uncertainty measures by means of simulations. The approach proposed in this study is based on an a priori deï¬nition of the cardinality ğ‘› of ğ‘‹. Then, the set of focal elements îˆ² is constructed by randomly sampling subsets of the FOD ğ‘‹ until the union of the sampled subsets is a cover of ğ‘‹, that is, until each element of ğ‘‹ appears in at least one of the selected subsets. A BPA ğ‘š over the elements of îˆ² is assigned using the Dirichlet function with parameter vector ğŸ|îˆ²|. It is important to note that the choice of the Dirichlet function parameterized with ğŸ|îˆ²| determines that the sampling of the values of ğ‘š over îˆ² occurs uniformly and that the sum of their values is one. In other words, once a set of focal elements îˆ² covering ğ‘‹ is sampled, then the positive values assigned to the |îˆ² | focal elements are uniformly sampled from the |îˆ² |-dimensional unit simplex.
This procedure for sampling BOEs is the same as that proposed by Burger and Destercke [48], in which the stopping condition is that the union of the elements in the FOD covers the set ğ‘‹. The simulation consists of ï¬xing ğ‘› and then repeating the procedure ğ‘  = 10, 000 times so that, for each repetition, the uncertainty of the BPA is measured by means of the uncertainty measures presented in Section 3. The simulation procedure is summarized in Algorithm 1 and the simulation code is available online.2
Let us note that some of the methods used here to analyze uncertainty measures have already been adopted within evidence theory to study some other aspects of belief functions. See, for example, the contribution by Jousselme and Maupin [49], in which scatter plots and dendrograms were used to compare distances between belief functions.
4.1. Similarity analysis
First, we analyze the similarities between uncertainty measures by checking their comonotonicity. We assume that the similarity between two uncertainty measures depends on their tendency to order BPAs in a similar way from the most to the least uncertain. That is, given ğ‘  BPAs, two uncertainty measures are similar if they agree on how to order the ğ‘  BPAs from the most to the least uncertain. Given the possible existence of non-linear relations between values obtained from diï¬€erent uncertainty measures, we prefer to use a comonotonicity measure that is agnostic to the nature of the comonotonicity. For this reason, for example, we excluded Pearsonâ€™s linear correlation, which assumes any comonotonicity to be linear. For a similar reason, we ruled out polynomial and parametric regressions. Considering these requirements, we used the Spearman rank correlation coeï¬ƒcient ğœŒ, which, given two numerical lists ğš, ğ› âˆˆ â„ğ‘ , returns a value in [âˆ’1, 1].
2 https://gitlab.com/or-group-dii-unitn-public/evidence-theory.
9

M. Urbani, G. Gasparini and M. Brunelli

Information Sciences xxx (xxxx) xxx

Algorithm 1 The simulation procedure to compare the selected uncertainty measures.

ğ‘‹ â† {ğ‘¥1, â€¦ , ğ‘¥ğ‘›} ğ‘ â†ğ‘ 

ğ‘„ â† {ğ‘1, â€¦ , ğ‘ğ‘š} îˆ° â†âˆ…

ğ‘–â†1

while ğ‘– â‰¤ ğ‘ do

ğ‘…â†âˆ… while

â‹ƒ
ğ´âˆˆğ‘…

ğ´

âŠŠ

ğ‘‹

do

ğ´ â† ğ‘ ğ‘ğ‘šğ‘ğ‘™ğ‘’(2ğ‘‹ â§µ ğ‘…)

ğ‘…â†ğ‘…âˆªğ´

end while

îˆ² â†âˆ…

ğµ â† ğ·ğ‘–ğ‘Ÿğ‘–ğ‘â„ğ‘™ğ‘’ğ‘¡(|ğ‘…|)

for ğ‘ âˆˆ ğµ do

îˆ² â† îˆ² âˆª {âŸ¨ğ´, ğ‘âŸ©}

end for

îˆ° â† îˆ° âˆª {âŸ¨ğ‘1(îˆ² ), â€¦ , ğ‘ğ‘š(îˆ² )âŸ©} ğ‘–â†ğ‘–+1

end while

âŠ³ Deï¬ne the frame of discernment âŠ³ Initialize ğ‘
âŠ³ Deï¬ne a list of entropy measures âŠ³ Create an empty dataset

âŠ³ Sample a set ğ´ âŠ† 2ğ‘‹ â§µ ğ‘…

âŠ³

Sample

|ğ‘…|

values

using

Dirichlet

so

that

âˆ‘
ğ‘âˆˆğµ

ğ‘

=

1

âŠ³ Compute a new array of entropy measures

The Spearman coeï¬ƒcient assumes a preprocessing phase in which raw values ğ‘ğ‘–, ğ‘ğ‘– are transformed into ranks ğ‘…(ğ‘ğ‘–), ğ‘…(ğ‘ğ‘–) so that ğ‘…(ğš) and ğ‘…(ğ›) are the vectors containing the ordinal rankings of the components of ğš and ğ›, respectively. Then,

ğœŒ(ğš, ğ›) =

cov(ğ‘…(ğš), ğ‘…(ğ›)) , ğœğ‘…(ğš) ğœğ‘…(ğ›)

where cov gives the covariance of the two ranking vectors and ğœ is the standard deviation. More precisely, the value ğœŒ(ğš, ğ›) = 1 denotes perfect positive comonotonicity between the two lists, ğœŒ(ğš, ğ›) = âˆ’1 denotes perfect negative comonotonicity, and ğœŒ(ğš, ğ›) = 0 no comonotonicity.
Fixing ğ‘› = 4, Fig. 2 shows scatter plots for all pairs of the considered uncertainty measures, together with their Spearman coefï¬cients. Note that we exclude the measures deï¬ned by Eqs. (7)â€“(13) and (17) from the analysis to save space and because these measures can only partially capture uncertainty or have been superseded by more reï¬ned ones. Consequently, all the measures in Fig. 2 are measures of total uncertainty. A closer analysis of a selection of these scatter plots can shed more light on the similarities and dissimilarities between uncertainty measures and help quantify the extent of their possible drawbacks.
Fig. 3a compares the uncertainty measure proposed by JirouÅ¡ek and Shenoy with that of Wang and Song. With ğœŒ â‰ˆ 0.99, this is a representative example of two extremely similar uncertainty measures that, however, have signiï¬cantly diï¬€erent formulations, which may not have led one to suspect their similarity. This may suggest that, for practical purposes, the two measures are almost interchangeable. It is also worth noting that, as shown in Table 1, in spite of their similarity, the two measures have remarkably diï¬€erent mathematical properties.
Fig. 3b shows an example of two uncertainty measures that are negatively correlated (ğœŒ â‰ˆ âˆ’0.204), even if their polarity should be the same. The scatter plot shows a cloud of points with a barely perceivable (negative) comonotonicity. In this case, it is not only diï¬ƒcult to accept the conclusion that the two measures capture the same phenomenon for which they were proposed, but according to the Spearman coeï¬ƒcients, they appear more likely to produce opposite results. Indeed, if applied to real-world problems, these two measures are likely to give contrasting assessments. However, given the complex formulation of both uncertainty measures it is, once again, diï¬ƒcult to ï¬nd an explanation for this behavior.
The uncertainty measure ğ– ğ–´ proposed by Harmanec and Klir satisï¬es a number of desirable properties, but has been criticized in the literature for its insensitivity to changes in the mass assignment. In particular, changes in ğ‘š often do not lead to changes in the estimated uncertainty. In fact, anytime the mass assignment ğ‘š is compatible with a uniform probability distribution on the singletons, this latter is considered and the value of the uncertainty measure saturates and reaches its maximum. However, this insensitivity of the measure by Harmanec and Klir has not been suï¬ƒciently studied and its extent and consequences are presently unknown. Fig. 3c compares the uncertainty measure proposed by Harmanec and Klir with that of Li et al. One can see that the uncertainty measure of Harmanec and Klir seems to have a maximum value that attracts closer values: this corresponds to the long vertical alignment of points on the right-hand side of the plot. In fact, there is a signiï¬cant gap between its maximum value and the second largest value. In this way, diï¬€erent mass assignments which, according to the uncertainty measure of Li et al., have greatly diï¬€erent levels of uncertainty may be associated with the maximum value, even if they are very much distinct in terms of total uncertainty. The comparative behavior of the uncertainty measure by Harmanec and Klir with other measures suggests that this undesirable behavior, already discussed in the literature, is a non-negligible phenomenon impairing the discriminating power of the measure ğ– ğ–´.
At present, it may be hard to interpret values returned by diï¬€erent uncertainty measures. For instance, if we consider the measure ğ– ğ–¬ proposed by Jousselme et al., which, for ğ‘› = 4, lies in the interval [0, 2], should we consider a value of, say, 1.25 representative of a high or low total uncertainty? While one may be tempted to lean toward the former, it could be more appropriate to prefer the latter, in light of the left-skewed distribution of values on the corresponding diagonal entry in Fig. 2 and detailed in Fig. 4a.
Note that the value 1.25 belongs to the decile containing the least uncertain mass assignments and for this reason, it cannot be considered representative of a high level of uncertainty. Conversely, a value of 1.25 for the uncertainty measure proposed by Lamata and Moral [19] represents a higher level of uncertainty, as can be seen in Fig. 4b. Note that both measures are expressed

10

M. Urbani, G. Gasparini and M. Brunelli

Information Sciences xxx (xxxx) xxx

Fig. 2. Pairwise scatter plots for pairs of uncertainty measures and their Spearman rank correlation coeï¬ƒcients for ğ‘› = 4. To enhance readability, the scatter plots are based on ğ‘  = 300 simulations whereas, for greater stability, the values in the upper triangular part were obtained with ğ‘  = 10, 000.
Fig. 3. Three representative scatter plots with ğ‘  = 1000. 11

M. Urbani, G. Gasparini and M. Brunelli

Information Sciences xxx (xxxx) xxx

Fig. 4. Two representative bar charts with ğ‘› = 4 and ğ‘  = 10, 000.

on the same scale [0, log2 ğ‘›] and are therefore comparable. Analyzing the bar charts on the diagonal of Fig. 2, one can observe diï¬€erent patterns. Such patterns are not a mere matter of curiosity, but cast serious doubt on the possibility of interpreting values of uncertainty measures without knowing their distributions. A formal way to compare two uncertainty measures is to approximate their distributions to the normal distributionâ€”using, for example, a power transform such as the Boxâ€“Cox transformationâ€”or any other distribution, and then to use the transformed values for comparison. We conclude that knowing the range of uncertainty measures is not suï¬ƒcient to interpret the levels of uncertainty of diï¬€erent mass assignments.
The results of this numerical study might also be useful when looking for support for a choice of uncertainty measure. In fact, one could argue against choosing a single measure and instead relying on the conjoint use of a range of measures to increase the robustness of the uncertainty analysis. Two measures with low similarityâ€”here quantiï¬ed by the Spearman rank correlationâ€”are more likely to provide separate evidence and, possibly, stronger conï¬rmation of whether a BOE is too uncertain. Conversely, considering a second extremely similar measure would add redundancy to the analysis. The more two measures are regarded as dissimilar but in fact produce similar uncertainty values, the more we may think that there is agreement on the measured phenomenon, and distinct evidence backing up the ï¬rst measurement.

4.2. Hierarchical clustering

We consider the Spearman coeï¬ƒcient as the basis for estimating the dissimilarities between uncertainty measures. In particular, if
we denote by ğœŒğ–§ğ‘–,ğ–§ğ‘— the value of the Spearman coeï¬ƒcient calculated for two measures of uncertainty ğ–§ğ‘– and ğ–§ğ‘— , then we can consider ğ‘‘ğ‘–ğ‘— = |1 âˆ’ ğœŒğ–§ğ‘–,ğ–§ğ‘— | < 2 a measure of their dissimilarity. We can use hierarchical clustering to analyze the values of ğ‘‘ğ‘–ğ‘— . Hierarchical clustering is a non-parametric technique that, however, depends on the choice of the heuristic that determines when two clusters,
say ğ‘‹ and ğ‘Œ , are merged. Initially, each element is a cluster of its own, and then they are progressively merged according to one of
the following heuristics:

â€¢ Single linkage: The value at which the two clusters ğ‘‹ and ğ‘Œ are merged corresponds to the minimum distance between an element

of ğ‘‹ and one of ğ‘Œ , that is, min{ğ‘‘ğ‘–ğ‘— |ğ‘– âˆˆ ğ‘‹, ğ‘— âˆˆ ğ‘Œ }. â€¢ Complete linkage: The value at which the two clusters ğ‘‹ and ğ‘Œ are merged corresponds to the maximum distance between an

element of ğ‘‹ and one of ğ‘Œ , that is, max{ğ‘‘ğ‘–ğ‘— |ğ‘– âˆˆ ğ‘‹, ğ‘— âˆˆ ğ‘Œ }. â€¢ Average linkage: The value at which the two clusters ğ‘‹ and ğ‘Œ are merged corresponds to the average distance between elements

belonging to the two clusters, that is,

1 |ğ‘‹||ğ‘Œ

|

âˆ‘
ğ‘–âˆˆğ‘‹

âˆ‘
ğ‘—âˆˆğ‘Œ

ğ‘‘ğ‘–ğ‘—

.

â€¢ Ward linkage: The value at which two clusters ğ‘‹ and ğ‘Œ are merged corresponds to the cluster distance. The distance between

two clusters ğ‘‹ and ğ‘Œ is

âˆš

ğ‘‘(ğ‘‹, ğ‘Œ ) =

|ğ‘Œ

|

+ ğ‘‡

|ğ‘|

ğ‘‘(ğ‘Œ

, ğ‘)2

+

|ğ‘Œ

|

+ |ğ‘Š ğ‘‡

|

ğ‘‘(ğ‘Œ

,ğ‘Š

)2

âˆ’

|ğ‘Œ ğ‘‡

|

ğ‘‘ (ğ‘ ,

ğ‘Š

)2,

where ğ‘‹ is the newly joined cluster consisting of ğ‘ and ğ‘Š , ğ‘Œ is the cluster to be merged with, and ğ‘‡ = |ğ‘Œ | + |ğ‘| + |ğ‘Š |. When
two clusters each contain a single element, ğ‘‘(ğ‘‹, ğ‘Œ ) = ğ‘‘ğ‘‹ğ‘Œ . The Ward variance minimization algorithm [50] is used to perform clustering3

3 https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.linkage.html. 12

M. Urbani, G. Gasparini and M. Brunelli

Information Sciences xxx (xxxx) xxx

Fig. 5. A comparison of dendrograms obtained using diï¬€erent clustering heuristics. The values on the ğ‘¦-axis correspond to the distance between clusters according to the chosen heuristic. Along with the name of each measure, the EB/IB classiï¬cation is reported as in Table 1; all measures express total uncertainty.
The application of these four heuristics to the values in Fig. 2 is reported in the dendrograms in Fig. 5, from which some conclusions can be drawn. Approaches based on distances between intervals do not belong to a separate cluster and are instead mixed with the others in a cluster of extremely similar measuresâ€”on the left-hand side in the dendrogram for the single linkage heuristic. In general, there is not a sharp separation of measures according to their formulations. Thus, it may be deceiving to judge the diï¬€erences between methods based on their mathematical formulations. For instance, the three measures proposed by Pal et al. (Eq. (15)), Qin et al. (Eq. (29)), and Li and Pan (Eq. (30)) are based on similar formulations but only the former two are numerically similar. Interestingly, the separation into clusters seems to follow the years of inception of diï¬€erent measures: with few exceptions, all the most recent measures are part of a large cluster of similar measures. This issue will be further investigated in the next subsection.
4.3. Centrality analysis
The Spearman coeï¬ƒcients in Fig. 2, which are always in the range [âˆ’1, 1], can be interpreted as degrees of closeness between methods. By doing so, we can consider the matrix of Spearman coeï¬ƒcients underlying Fig. 2 as an adjacency matrix.
Adjacency matrices are well-known mathematical structures used in network analysis and therefore it is natural to employ tools developed in network analysis, for example in the study of social networks. In particular, centrality measures, as the name suggests, are used in network analysis to measure the extent to which nodes can be considered â€œcentralâ€ in the context of the graph of which they are elements.
If we consider weighted graphs in which the adjacency degree of two nodes can be interpreted as the degree of mutual support, a centrality measure shows the degree of support that each node receives from the others. The Spearman coeï¬ƒcient can be seen as a measure of the mutual support between two uncertainty measures when it comes to ranking BOEs from the least to the most uncertain: the higher the value, the more the results of one uncertainty measure support those of the other. Among the various measures of centrality, the eigenvector centrality, which corresponds to the eigenvector associated with the Perronâ€“Frobenius eigenvalue of a
13

M. Urbani, G. Gasparini and M. Brunelli

Information Sciences xxx (xxxx) xxx

Fig. 6. A bar chart representing the values of normalized eigenvector centrality of each uncertainty measure.
Fig. 7. The measure of non-speciï¬city proposed by Dubois and Prade [17] compared with four measures of conï¬‚ict. The respective Spearman coeï¬ƒcients are âˆ’0.488, âˆ’0.933, âˆ’0.705, and âˆ’0.525.
weighted adjacency matrix, has assumed a prominent role thanks to its capacity to account for indirect relations, its good axiomatic properties, and the fact that it is ï¬‚exible enough to be used with signed graphs too. In practice, given a weighted adjacency matrix ğ€, in our case stemming from Fig. 2, the centrality values of the uncertainty measures correspond to the components of the vector ğ° solving the eigensystem ğ€ğ° = ğœ†maxğ°, where ğœ†max is the Perronâ€“Frobenius eigenvalue of ğ€. Note that ğ° is unique up to multiplication by a positive scalar.
Fig. 6 reports the normalized eigenvector centrality for the uncertainty measures considered in this study, including the older ones. The more central an uncertainty measure is, the more support it receives from the other measures. Therefore, a high value of centrality can be seen as an indication that a measure is holistic, as it can, to some extent, also represent the points of view oï¬€ered by alternative measures. In this sense, in absence of decisive results, high centrality values should be seen favorably. On the other hand, it is also true that low centrality values are symptomatic of original approaches providing separate evidence. The results in Fig. 6 show a wide range of behaviors. A number of measures have negative centrality values, which is indicative of a negative comonotonicity with other measures. Remarkably, all the uncertainty measures with negative centrality are measures of conï¬‚ict. Hence, it seems that when a term is added to a measure of conï¬‚ict to account for the non-speciï¬city, this does not only alter the measurement, but it does it in a very speciï¬c (and opposite) direction: the lower the non-speciï¬city, the higher the conï¬‚ict, and vice versa. This is illustrated in Fig. 7 and seems to further corroborate the need to account for both facets of uncertainty to avoid underor overestimations. To understand the relevance of this observation, one may, for instance, consider evidence-based fusion systems in which one is interested in assessing the uncertainty level before choosing whether to fuse or not.
Furthermore, it is possible to see that, with a few exceptions, the most recent measures have high centrality values and the old ones have negative values. This could be symptomatic of a recent convergence of research toward a shared deï¬nition of uncertainty measure. Among the exceptions to this phenomenon, the measure of Dubois and Prade is remarkable: in spite of its extreme simplicity
14

M. Urbani, G. Gasparini and M. Brunelli

Information Sciences xxx (xxxx) xxx

Fig. 8. Sensitivity analysis for randomly selected similarity values between uncertainty measures. Each line represents the similarity of a diï¬€erent pair of uncertainty measures and how it changes with respect to the cardinality of the FOD.
and the fact that it can capture only some aspects of uncertainty, it seems to be supported by other measures. One reason for this could be the fact that the formulation of this uncertainty measure is embedded in many of the most recent ones.
A cautionary note may be necessary. As the centrality values depend on the measures considered in the analysis, the values presented in Fig. 6 can vary according to the included measures. On the other hand, it is also sensible to assume that such variations would not be so signiï¬cant as to invalidate the conclusions drawn from our results.
So far, the results have been presented for ğ‘› = 4, which is a recurring size of the FOD in most of the illustrative examples presented in the literature. To explore the generalizability of the results, we explored the cases with ğ‘› = 3, â€¦ , 8. Fig. 8 shows a graphical sensitivity analysis for 30 Spearman rank correlation coeï¬ƒcients for randomly chosen pairs of uncertainty measures.
Considering Fig. 8, the values for ğ‘› = 4 correspond to 30 random values from Fig. 2. Then, for the same pairs of measures, the simulations were repeated for other values of ğ‘› and the new similarities were collected and compared. While the results in Fig. 8 are qualitative, they certainly show some changes in the similarities but, with a few exceptions (low levels tend to become lower when ğ‘› increases), it is diï¬ƒcult to spot clear patterns. In particular, high levels of similarity remain high regardless of the value of ğ‘›. For reasons of space, a full comparative analysis with respect to the parameter ğ‘› is not presented here, but the interested reader can refer to some supplementary material online.4
5. Conclusions
First, we outlined the most prominent uncertainty measures in the evidence theory, hoping that this could help other researchers navigate this mare magnum. Next, the results of Monte Carlo simulations were presented, in which the behavior of diï¬€erent uncertainty measures were compared pairwise, allowing us to analyze their similarities and diï¬€erences. The formal tools employed in the analysis include rank correlation, hierarchical clustering, and eigenvector centrality.
Besides the results, already analyzed in the previous section, we want to stress the necessity of numerical studies to interpret values returned by diï¬€erent uncertainty measures, which could otherwise be interpreted only in an ordinal sense. That is, given an uncertainty measure ğ–§ and two mass assignments ğ‘š1 and ğ‘š2 on the same FOD, ğ–§(ğ‘š1) â‰¥ ğ–§(ğ‘š2) implies that, according to ğ–§, ğ‘š1 is more uncertain than ğ‘š2, but it is presently hard to draw more conclusions on the uncertainty levels of both ğ‘š1 and ğ‘š2. Maybe ğ‘š1 and ğ‘š2 are both too uncertain to be suï¬ƒciently speciï¬c. Or maybe they are not. In fact, in some applications, it may be reasonable to disregard mass assignments when they are too uncertain to yield suï¬ƒcient information. This problem is similar to the quantiï¬cation of the inconsistency of preferences in decision analysis, as happens in the analytic hierarchy process, in which preferences that are too inconsistent may be rejected and sent for re-evaluation, seeking a greater level of consistency. This may also trigger some research on some acceptability thresholds, which could be estimated as quantiles of the empirical distributions or with methods such as AUC (area under the curve) of the ROC (receiver operating characteristic).
Given the existing literature on uncertainty measures and the results presented in this manuscript, it is reasonable to expect that future proposals of new measures should compare the newly introduced measure with the existing ones (i) numerically, to detect possible similarities/dissimilarities, and (ii) formally, to show a clear advantage with respect to the existing literature.
CRediT authorship contribution statement
Michele Urbani: Conceptualization, Data curation, Formal analysis, Investigation, Methodology, Software, Validation, Visualization, Writing â€“ original draft. Gaia Gasparini: Data curation, Investigation, Visualization, Writing â€“ original draft. Matteo Brunelli: Conceptualization, Formal analysis, Funding acquisition, Methodology, Project administration, Supervision, Validation, Visualization, Writing â€“ original draft, Writing â€“ review & editing.
4 https://gitlab.com/or-group-dii-unitn-public/evidence-theory.
15

M. Urbani, G. Gasparini and M. Brunelli

Information Sciences xxx (xxxx) xxx

Declaration of competing interest

The authors declare that they have no known competing ï¬nancial interests or personal relationships that could have appeared to inï¬‚uence the work reported in this paper.

Data availability

Data will be made available on request.

Acknowledgements

We appreciated the suggestions of three anonymous reviewers and the Editor, which helped us improve the quality of the manuscript. The research of Gaia Gasparini is supported by Autostrada del Brennero S.p.A., Italy.

References

[1] B.M. Ayyub, G.J. Klir, Uncertainty Modeling and Analysis in Engineering and the Sciences, Chapman and Hall/CRC, 2006. [2] D. Dubois, H. Prade, Possibility Theory: An Approach to Computerized Processing of Uncertainty, Springer Science & Business Media, 1988. [3] A.P. Dempster, Upper and lower probabilities induced by a multivalued mapping, Ann. Math. Stat. 38 (1967) 325â€“339. [4] G. Shafer, A Mathematical Theory of Evidence, Princeton University Press, 1976. [5] C.E. Shannon, A mathematical theory of communication, Bell Syst. Tech. J. 27 (1948) 379â€“423. [6] R. JirouÅ¡ek, P.P. Shenoy, A new deï¬nition of entropy of belief functions in the Dempsterâ€“Shafer theory, Int. J. Approx. Reason. 92 (2018) 49â€“65. [7] K. Wen, Y. Song, C. Wu, T. Li, A novel measure of uncertainty in the Dempster-Shafer theory, IEEE Access 8 (2020) 51550â€“51559. [8] Q. Pan, D. Zhou, Y. Tang, X. Li, J. Huang, A novel belief entropy for measuring uncertainty in Dempster-Shafer evidence theory framework based on plausibility
transformation and weighted Hartley entropy, Entropy 21 (2019) 163. [9] D. Wang, J. Gao, D. Wei, A new belief entropy based on Deng entropy, Entropy 21 (2019) 987. [10] Q. Zhou, Ã‰. BossÃ©, Y. Deng, Modeling belief propensity degree: measures of evenness and diversity of belief functions, IEEE Trans. Syst. Man Cybern. Syst.
(2022). [11] A.G. Bronevich, A.E. Lepskiy, Measures of conï¬‚ict, basic axioms and their application to the clusterization of a body of evidence, Fuzzy Sets Syst. 446 (2022)
277â€“300. [12] G.J. Klir, A. Ramer, Uncertainty in the Dempster-Shafer theory: a critical re-examination, Int. J. Gen. Syst. 18 (1990) 155â€“166. [13] U. HÃ¶hle, Entropy with respect to plausibility measures, in: Proc. of 12th IEEE Int. Symp. on Multiple Valued Logic, Paris, 1982, 1982, pp. 167â€“169. [14] R.R. Yager, Entropy and speciï¬city in a mathematical theory of evidence, Int. J. Gen. Syst. 9 (1983) 249â€“260. [15] P. Smets, Information content of an evidence, Int. J. Man-Mach. Stud. 19 (1983) 33â€“43. [16] H.T. Nguyen, On entropy of random sets and possibility distributions, in: The Analysis of Fuzzy Information, vol. 1, 1987, pp. 145â€“156. [17] D. Dubois, H. Prade, Properties of measures of information in evidence and possibility theories, Fuzzy Sets Syst. 24 (1987) 161â€“182. [18] G.J. Klir, B. Parviz, A note on the measure of discord, in: D. Dubois, M.P. Wellman, B. Dâ€™Ambrosio, P. Smets (Eds.), Uncertainty in Artiï¬cial Intelligence, Morgan
Kaufmann, 1992, pp. 138â€“141. [19] M.T. Lamata, S. Moral, Measures of entropy in theory of evidence, Int. J. Gen. Syst. 14 (1988) 297â€“305. [20] N.R. Pal, J.C. Bezdek, R. Hemasinha, Uncertainty measures for evidential reasoning II: a new measure of total uncertainty, Int. J. Approx. Reason. 8 (1993) 1â€“16. [21] D. Harmanec, G. Klir, Measuring total uncertainty in Dempster-Shafer theory: a novel approach, Int. J. Gen. Syst. 22 (1994) 405â€“419. [22] V.-N. Huynh, Y. Nakamori, Notes on â€œreducing algorithm complexity for computing an aggregate uncertainty measureâ€, IEEE Trans. Syst. Man Cybern., Part A,
Syst. Hum. 40 (2009) 205â€“209. [23] T. George, N.R. Pal, Quantiï¬cation of conï¬‚ict in Dempster-Shafer framework: a new approach, Int. J. Gen. Syst. 24 (1996) 407â€“423. [24] A.-L. Jousselme, C. Liu, D. Grenier, E. BossÃ©, Measuring ambiguity in the evidence theory, IEEE Trans. Syst. Man Cybern., Part A, Syst. Hum. 36 (2006) 890â€“903. [25] Y. Yang, D. Han, A new distance-based total uncertainty measure in the theory of belief functions, Knowl.-Based Syst. 94 (2016) 114â€“123. [26] Z. Deng, J. Wang, Measuring total uncertainty in evidence theory, Int. J. Intell. Syst. 36 (2021) 1721â€“1745. [27] R. Li, Z. Chen, H. Li, et al., A new distance-based total uncertainty measure in Dempster-Shafer evidence theory, Appl. Intell. 52 (2022) 1209â€“1237. [28] X. Deng, F. Xiao, Y. Deng, An improved distance-based total uncertainty measure in belief function theory, Appl. Intell. 46 (2017) 898â€“915. [29] X. Wang, Y. Song, Uncertainty measure in evidence theory with its applications, Appl. Intell. 48 (2017) 1672â€“1688. [30] Y. Deng, Deng entropy, Chaos Solitons Fractals 91 (2016) 549â€“553. [31] J. AbellÃ¡n, Analyzing properties of Deng entropy in the theory of evidence, Chaos Solitons Fractals 95 (2017) 195â€“199. [32] S. Moral-GarcÃ­a, J. AbellÃ¡n, Critique of modiï¬ed Deng entropies under the evidence theory, Chaos Solitons Fractals 140 (2020) 110112. [33] L. Pan, Y. Deng, A new belief entropy to measure uncertainty of basic probability assignments based on belief function and plausibility function, Entropy 20
(2018). [34] D. Zhou, Y. Tang, W. Jiang, A modiï¬ed belief entropy in Dempster-Shafer framework, PLoS ONE 12 (2017). [35] H. Cui, Q. Liu, J. Zhang, B. Kang, An improved Deng entropy and its application in pattern recognition, IEEE Access 7 (2019) 18284â€“18292. [36] H. Yan, Y. Deng, An improved belief entropy in evidence theory, IEEE Access 8 (2020) 57505â€“57516. [37] M. Qin, Y. Tang, J. Wen, An improved total uncertainty measure in the evidence theory and its application in decision making, Entropy 22 (2020) 487. [38] J. Li, Q. Pan, A new belief entropy in Dempsterâ€“Shafer theory based on basic probability assignment and the frame of discernment, Entropy 22 (2020) 691. [39] Q. Zhou, Y. Deng, Fractal-based belief entropy, Inf. Sci. 587 (2022) 265â€“282. [40] Y. Zhao, D. Ji, X. Yang, L. Fei, C. Zhai, An improved belief entropy to measure uncertainty of basic probability assignments based on Deng entropy and belief
interval, Entropy 21 (2019). [41] Y. Zhang, F. Huang, X. Deng, W. Jiang, A new total uncertainty measure from a perspective of maximum entropy requirement, Entropy 23 (2021). [42] Y. Deng, Uncertainty measure in evidence theory, Sci. China Inf. Sci. 63 (2020) 1â€“19. [43] G.J. Klir, H.W. Lewis, Remarks on â€œmeasuring ambiguity in the evidence theoryâ€, IEEE Trans. Syst. Man Cybern., Part A, Syst. Hum. 38 (2008) 995â€“999. [44] X. Deng, Analyzing the monotonicity of belief interval based uncertainty measures in belief function theory, Int. J. Intell. Syst. 33 (2018) 1869â€“1879. [45] J. AbellÃ¡n, Ã‰. BossÃ©, Critique of recent uncertainty measures developed under the evidence theory and belief intervals, IEEE Trans. Syst. Man Cybern. Syst. 50
(2017) 1186â€“1192. [46] S. Moral-GarcÃ­a, J. AbellÃ¡n, Required mathematical properties and behaviors of uncertainty measures on belief intervals, Int. J. Intell. Syst. 36 (2021). [47] J. Dezert, A. Tchamova, On the eï¬€ectiveness of measures of uncertainty of basic belief assignments, Inf. Secur. 52 (2022) 9â€“36. [48] T. Burger, S. Destercke, How to randomly generate mass functions, Int. J. Uncertain. Fuzziness Knowl.-Based Syst. 21 (2013) 645â€“673. [49] A.-L. Jousselme, P. Maupin, Distances in evidence theory: comprehensive survey and generalizations, Int. J. Approx. Reason. 53 (2012) 118â€“145. [50] J.H. Ward Jr, Hierarchical grouping to optimize an objective function, J. Am. Stat. Assoc. 58 (1963) 236â€“244.

16


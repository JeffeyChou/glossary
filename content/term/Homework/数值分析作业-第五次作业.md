---
date: 2023-04-17 20:37:06
categories: Homework
destination: 
excerpt: 第五次作业
katex: true
obsidianUIMode: source
rating: ⭐⭐⭐
draft: false
tags:  
- Numerical_Analysis 
- 作业
title: "数值分析作业-第五次作业"
share: true
---

<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);"
    src="https://search.pstatic.net/common?src=https://i.imgur.com/4X9I6My.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">作业内容截图
    </div>
</center>

# 第一题

$$A=\begin{pmatrix}4 & -2 & 0 \\ -2 & 2 & -1 \\ 0 & -1 & 	5\end{pmatrix}$$
矩阵 $A$ 的特征方程为 $-\lambda^{3}+ 11 \lambda ^{2} - 33 \lambda +16$ 求解得到三个特征值均为正数，所以该矩阵是正定矩阵。

$R_{11}=\sqrt{A_{11}}=2$, 得到 $R_{1,2:3}=[-2, 0]/R_{11}=[-1,0]$, 得到要计算的外积 $u u^{\top}=\begin{pmatrix}-1 \\ 0\end{pmatrix} \cdot \begin{pmatrix}-1 & 	0\end{pmatrix}$, 再将  $A_{2:3,2:3}$ 减去该值，得到更新后的 $A_{2:3,2:3}$ 矩阵：
$$\begin{pmatrix} 0&  0&  0\\  0& 2 & -1 \\  0& -1 & 5\end{pmatrix}-\begin{pmatrix}0 & 0 & 0 \\ 0 & 1 & 0\\  0& 0 &0\end{pmatrix}=\begin{pmatrix}0 & 0 & 0 \\ 0 & 1 & -1 \\ 0 & -1 & 	5\end{pmatrix}$$
得到 $R_{2,2}=\sqrt{A_{22}}=1$, $R_{2,3}=-1/R_{2,2}=-1$, $A_{3,3}=5-(-1)\cdot(-1)=4$, $R_{3,3}=\sqrt{A_{3,3}}=2$

得到 $R$:

$$R=\begin{pmatrix}2 & -1 & 0 \\ 0 & 1 & -1 \\ 0 & 0 & 	2\end{pmatrix}$$
那么 $$A=R^{\top}R=\begin{pmatrix}2 & 0 & 0 \\ -1 & 1 & 0 \\ 0 & -1 & 	2\end{pmatrix} \cdot \begin{pmatrix}2 & -1 & 0 \\ 0 & 1 & -1 \\ 0 & 0 & 	2\end{pmatrix}$$
进行回代求解：
$$\begin{pmatrix}2 & 0 & 0 \\ -1 & 1 & 0 \\ 0 & -1 & 	2\end{pmatrix}\begin{pmatrix}y_1 \\ y_2 \\ y_3\end{pmatrix}=\begin{pmatrix}0 \\3 \\ -7\end{pmatrix}$$
得到 $\begin{pmatrix}y_1 & y_2 & y_3\end{pmatrix}$ 的解为：$\begin{pmatrix}0 & 3 & 	-2 \end{pmatrix}$
回代求解：
$$\begin{pmatrix}2 & -1 & 0 \\ 0 & 1 & -1 \\ 0 & 0 & 	2\end{pmatrix}\begin{pmatrix}x_1 \\ x_2 \\ x_3\end{pmatrix}=\begin{pmatrix}0  \\ 3 \\ -2\end{pmatrix}$$
得到最终解为： $\begin{pmatrix}1 & 2 & 	-1\end{pmatrix}$

# 第二题

## 共轭方向法
$u_{1}=e_{1}=\begin{pmatrix}1  \\ 0\end{pmatrix}$, $u_2=e_2-\frac{\left\langle e_2, u_1\right\rangle_A}{\left\langle u_1, u_1\right\rangle_A} u_1=\left[\begin{array}{l}0 \\ 1\end{array}\right]-\left[\begin{array}{l}1 \\ 0\end{array}\right]=\left[\begin{array}{c}-1 \\ 1\end{array}\right]$, 迭代 $x_{0}=\begin{pmatrix}0 \\ 0\end{pmatrix}$
$x_1=x_0+\frac{\left\langle b-A x_0, u_1\right\rangle}{\left\langle u_1, u_1\right\rangle_A} u_1=\left[\begin{array}{l}0 \\ 0\end{array}\right]+3\left[\begin{array}{l}1 \\ 0\end{array}\right]=\left[\begin{array}{l}3 \\ 0\end{array}\right]$
$x_2=x_1+\frac{\left\langle b-A x_1, u_2\right\rangle}{\left\langle u_2, u_2\right\rangle_A} u_2=\left[\begin{array}{l}3 \\ 0\end{array}\right]+\left[\begin{array}{c}-1 \\ 1\end{array}\right]=\left[\begin{array}{c}2 \\ 1\end{array}\right]$

## 共轭梯度法
$$
\begin{aligned}
& x_0=\left[\begin{array}{l}
0 \\
0
\end{array}\right], r_0=v_0=\left[\begin{array}{l}
6 \\
10
\end{array}\right] \\
&  t_0=\frac{\left\langle r_0, r_0\right\rangle}{\left\langle v_0, A v_0\right\rangle}=\frac{17}{114}, x_1=x_0+t_0 v_0=\left[\begin{array}{l}
\frac{17}{19} \\
\frac{85}{57}
\end{array}\right] \\
& r_1=r_0-t_0 A v_0=\left[\begin{array}{c}
\frac{70}{57} \\
-\frac{14}{19}
\end{array}\right]
\end{aligned}
$$

$$
\begin{aligned}
& t_1=\frac{\left\langle r_1, r_1\right\rangle}{\left\langle v_1, A v_1\right\rangle}=\frac{17}{114}, x_1=x_0+t_0 v_0=\left[\begin{array}{l}
\frac{17}{19} \\
\frac{85}{57}
\end{array}\right] \\
& r_1=r_0-t_0 A v_0=\left[\begin{array}{c}
\frac{70}{57} \\
-\frac{14}{19}
\end{array}\right] \\
 &s_0=\frac{\left\langle r_1, r_1\right\rangle}{\left\langle r_0, r_0\right\rangle}=\frac{49}{3249}\\
&v_1=r_1+s_{0}v_0=\begin{pmatrix} \frac{476}{361}  \\ - \frac{1904}{3249}\end{pmatrix} \\
&x_2=x_{1} + \frac{\left\langle r_1, r_1\right\rangle}{\left\langle v_1, Av_1\right\rangle} \cdot v_{1}= 
x_{1}+\frac{57}{68}v_1 =\begin{pmatrix}2  \\ 1\end{pmatrix}
\end{aligned} 
$$

# 第三题


## 梯度下降法

```Mathematica
A = {{4, -2, 0}, {-2, 2, -1}, {0, -1, 5}}; 
b = {0, 3, -7}; x = {0, 0, 0}; 
alpha = 0.01; tolerance = 0.0001;

J[x_] := 1/2*Norm[A . x - b]^2;

While[
	J[x] > tolerance, 
	gradJ = Transpose[A] . (A . x - b); 
	x = x - alpha*gradJ; 
	Print["x = ", x, ", J(x) = ", J[x]];
	]
```
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);"
    src="https://search.pstatic.net/common?src=https://i.imgur.com/NA9WgQw.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">程序运行结果
    </div>
</center>

```Mathematica
conjugateGradient[A_, b_, x0_, tol_, MaxIterations_] := 
 Module[{x, r, p, alpha, beta, i}, x = x0;
  r = b - A . x;
  p = r;
  i = 0;
  While[Norm[r] > tol && i < MaxIterations, 
   alpha = (r . r)/(p . A . p);
   x = x + alpha*p;
   rnew = r - alpha*A . p;
   beta = (rnew . rnew)/(r . r);
   p = rnew + beta*p;
   r = rnew;
   i = i + 1;];
  {x, i}]
A = {{4, -2, 0}, {-2, 2, -1}, {0, -1, 5}};
b = {0, 3, -7}; x = {0, 0, 0};
tol = 0.0001;
MaxIteration = 1000;
{x, iterations} = conjugateGradient[A, b, x, tol, MaxIteration];
Print["Solution: ", x];
Print["Iterations: ", iterations];
```


<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);"
    src="https://search.pstatic.net/common?src=https://i.imgur.com/YkGYnVO.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">共轭梯度法程序运行结果
    </div>
</center>

首先从直观上来说，对于这个问题，共轭梯度法的速度远远快于梯度下降法。对于同一个$TOL=0.0001$, 梯度下降法需要的迭代次数超过共轭梯度法两个量级；其次从迭代的最终结果来说，共轭梯度法只需迭代三次就得到了精确的数值解，而梯度下降法在达到TOL精度后只能达到近似解。

综上，虽然共轭梯度法的算法复杂度和空间复杂度高于梯度下降法，但从时间维度上说，前者的计算成本小于梯度下降法。

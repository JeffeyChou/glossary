---
date: 2023-03-22 21:36:35
categories: ref
destination: 
excerpt: 人工智能presentation草稿
katex: true
obsidianUIMode: source
rating: ⭐⭐
draft: false
tags:  
- 作业
title: "python数据图谱示例"
share: true
---


# 知识图谱中的实体识别&关系抽取
# 目录
## CONTENT
1、什么是知识图谱
2、知识图谱的构建步骤
3、实体识别
4、总结

# 什么是知识图谱

2. Knowledge + Graph
3. Semantics: 语义
    1. 反对称性、不对称性、组成
4. Topology: 拓扑结构

知识图谱是一种以实体及其间关系、属性为基础的知识表达形式。

amphibiotic， semiaquatic: 水陆两栖

subaquatic: 水下的，半水生的

# 知识图谱的构建步骤

1. 数据获取：结构性，半结构性，无结构性
- 结构化数据：
结构化数据就是能用二维表逻辑表达实现的数据。【二维表（关系
型】
- 无结构数据：
无结构数据就是纯文本数据，没有标记。【无】
- 半结构数据：
半结构化数据就是带有标记的文本。【树、图】

2.  实体识别（Named Entity Recognition，NER）：通过自然语言处理技术，将文本中的实体（如人、地点、公司等）识别出来。
3.  属性抽取（Attribute Extraction ，AE）：对于每个实体，从文本中抽取出相关的属性（如年龄、地址、行业等）。
4.  关系抽取（Relation Extraction，RE）：分析文本中的句子结构，找到实体之间的关系（如老师-学生、公司-员工等）。
5.  知识图谱建模：将实体、属性和关系用图形方式表示，构建知识图谱模型。 
6.  知识图谱扩充：通过数据挖掘、自动化爬取等技术，从多个数据源中自动抽取知识，不断扩充知识图谱的规模和准确性。


# 实体识别
## 1. 基本概念
1.1 NER定义
在自然语言处理中，命名实体识别（Named Entity Recognition，NER）是指识别文本中指定类别的实体，这些类别包括人名、地名、组织机构名等等。
1.2 实体的类型
通常情况下，NER需要识别的实体类型包括人名、地名、组织机构名、时间、日期、事物、量词等等。

## 2. 常见method 

根据词汇资源，命名实体识别涉及的不同技术主要分为四类:

- *基于词典/字典的 NER*

NER 最直接的方法是使用词典或词典作为词汇表参考。字典包括一组有限的实体，可以使用基本的字符串匹配算法在给定的文本中识别这些实体。词典的有限词汇集限制了基于词典的方法的效率。只要字典得到适当的更新和维护，这种技术就能很好地工作。

- *基于规则的 NER*
基于规则的 NER 方法使用一组预定义的手工制作的语义规则来识别实体。使用基于规则的技术的信息抽取涉及两大类规则:
	- 基于模式的规则: 这些规则支持使用给定文本文件中单词的结构模式进行实体标识。
	- 基于上下文的规则: 这些规则支持使用给定文本文件中单词背后的上下文进行实体标识。

基于规则的 NER 方法需要手工构造语义规则，并且常常局限于特定的领域。

- *基于机器学习的 NER*

基于机器学习的 NER 方法包括使用统计模型来识别给定文本文档中的实体。机器学习模型通过观察文本数据来创建基于特征的实体表示。这些表示允许 NER 系统检测现有的实体，即使它们稍微拼写错误。

基于 ML 的 NER 需要对带注释的文本数据进行模型训练。然后使用经过训练的模型对新文件进行注释。通过这种方式，基于 ML 的 NER 系统通过自动演化其实体知识库来自我改进。

- *基于深度学习的 NER*

近年来，深度学习在许多机器学习模型中进行了创新。其中一个模型包括 NER 系统。基于深度学习的 NER 是一种资源友好和节省时间的命名实体识别方法，它不需要创建表示。基于深度学习的 NER 涉及从原始数据中自动学习实体表示，以发现给定文本数据中的复杂关系。这是一种相对现代的 NER 方法，使用先进的人工智能彻底改变了信息抽取。
3.1 基于词向量的模型
神经网络模型的一个重要特征是“分层特征提取”，基于此特征的模型引入了Word Embedding等词向量表示方法。这些模型包括BiLSTM-CRF、BiLSTM等等。
3.2 神经网络结构优化
针对不同的NER任务，研究者们也在神经网络结构上进行了不同的优化，如引入了LSTM、GRU等不同的RNN结构、加入Attention机制等等。

# DL-based NER

双向长短时记忆网络（BiLSTM）和条件随机场（CRF）

BiLSTM—CRF是基于深度学习的NER方法中最常见的架构，
BiLSTM（Bidirectional Long Short-Term Memory）是一种循环神经网络（Recurrent Neural Network，RNN）的变种

BiLSTM是一种序列模型，它可以处理序列中的每个元素，并通过记忆单元记住之前的信息。它在处理自然语言等文本数据时表现出色。但是，BiLSTM不能直接用于实体识别，因为它忽略了前后元素之间的关系。  
  
因此，需要用到CRF来解决这个问题。CRF是一个标记序列的生成模型，它可以通过考虑所有标记的联合概率来捕捉它们之间的依赖关系。这个模型可以比较好地应用于实体识别任务中。  
  
BiLSTM对输入的序列进行编码，得到隐状态的表示，然后将这些表示传递给CRF，CRF根据序列中的依赖关系来生成标记序列。  
  
这个过程可以看作是两个模型的叠加。BiLSTM首先处理输入序列，然后将隐藏状态和CRF一起使用以生成标记

由分布式表示层、双向LSTM层，以及CRF层构成。
句子表示向量→BiLSTM→每个单词的属于每个类别的分数→CRF→每个单词对应的预测标签


LSTM的计算过程可以概括为，通过对细胞状态中信息遗忘和记忆新的信息使得对后续时刻计算有用的
信息得以传递，而无用的信息被丢弃，并在每个时间步都会输出隐层状态

BiLSTM与LSTM类似，只是它有两个方向（正向和反向），即同时考虑上下文信息。具体地，BiLSTM包括两个LSTM，一个按照时间顺序处理输入，一个按照时间逆序处理输入，并分别输出各自的隐状态。同时，为了方便后续的模型训练，我们一般会将两个方向的输出进行拼接，得到每个时间步的特征表示，最终送到全连接层中进行分类或者回归等任务处理。

CRF层可以加入一些约束来保证最终预测结果是有效的。这些约束可以在训练数据时被CRF层自动学习得到。

句子的开头应该是“B-”或“O”，而不是“I-”。
“B-label1 I-label2 I-label3…”，在该模式中，类别1,2,3应该是同一种实体类别。比如，“B-Person I-
Person” 是正确的，而“B-Person I-Organization”则是错误的。
“O I-label”是错误的，命名实体的开头应该是“B-”而不是“I-”。
有了这些有用的约束，错误的预测序列将会大大减少。